{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.4\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/yoav/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - lightgbm[version='>=3.3.3']\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.11.17 |       hf0a4a13_0         151 KB  conda-forge\n",
      "    certifi-2023.11.17         |     pyhd8ed1ab_0         155 KB  conda-forge\n",
      "    lightgbm-4.1.0             |   py39h313beb8_0         1.2 MB\n",
      "    scipy-1.11.3               |   py39h20cbe94_0        19.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        20.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  lightgbm           pkgs/main/osx-arm64::lightgbm-4.1.0-py39h313beb8_0 \n",
      "  scipy              pkgs/main/osx-arm64::scipy-1.11.3-py39h20cbe94_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2023.7.22-hf0a4a13_0 --> 2023.11.17-hf0a4a13_0 \n",
      "  certifi                            2023.7.22-pyhd8ed1ab_0 --> 2023.11.17-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "lightgbm-4.1.0       | 1.2 MB    |                                       |   0% \n",
      "certifi-2023.11.17   | 155 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "lightgbm-4.1.0       | 1.2 MB    | 5                                     |   1% \u001b[A\u001b[A\u001b[A\n",
      "certifi-2023.11.17   | 155 KB    | ###8                                  |  10% \u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 151 KB    | ###9                                  |  11% \u001b[A\u001b[A\u001b[A\n",
      "lightgbm-4.1.0       | 1.2 MB    | ##########5                           |  28% \u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | #4                                    |   4% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 151 KB    | ###############################4      |  85% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "lightgbm-4.1.0       | 1.2 MB    | #####################                 |  57% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "lightgbm-4.1.0       | 1.2 MB    | ###################################   |  95% \u001b[A\u001b[A\n",
      "\n",
      "lightgbm-4.1.0       | 1.2 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ########1                             |  22% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ##########9                           |  30% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | #############4                        |  36% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ###############7                      |  43% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ##################5                   |  50% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | #####################3                |  58% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | #######################8              |  65% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ##########################6           |  72% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | #############################2        |  79% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ###############################8      |  86% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ##################################3   |  93% \u001b[A\u001b[A\n",
      "\n",
      "scipy-1.11.3         | 19.5 MB   | ####################################8 | 100% \u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install \\\n",
    "   --yes \\\n",
    "   -c conda-forge \\\n",
    "   'lightgbm>=3.3.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "pyGrZDiS4Asw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize, scale\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import pylab\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "-IWhcb9e571B",
    "outputId": "0f5637fe-f416-4388-d269-a7799d5ed0e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Name_x</th>\n",
       "      <th>DateTime_x</th>\n",
       "      <th>MonthYear_x</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Outcome Subtype</th>\n",
       "      <th>Animal Type_x</th>\n",
       "      <th>Sex upon Outcome</th>\n",
       "      <th>Age upon Outcome</th>\n",
       "      <th>...</th>\n",
       "      <th>DateTime_y</th>\n",
       "      <th>MonthYear_y</th>\n",
       "      <th>Found Location</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Animal Type_y</th>\n",
       "      <th>Sex upon Intake</th>\n",
       "      <th>Age upon Intake</th>\n",
       "      <th>Breed_y</th>\n",
       "      <th>Color_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A794011</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>05/08/2019 06:20:00 PM</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>05/02/2017</td>\n",
       "      <td>Rto-Adopt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>...</td>\n",
       "      <td>05/02/2019 04:51:00 PM</td>\n",
       "      <td>May 2019</td>\n",
       "      <td>Austin (TX)</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Brown Tabby/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A776359</td>\n",
       "      <td>Gizmo</td>\n",
       "      <td>07/18/2018 04:02:00 PM</td>\n",
       "      <td>Jul 2018</td>\n",
       "      <td>07/12/2017</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>...</td>\n",
       "      <td>07/12/2018 12:46:00 PM</td>\n",
       "      <td>July 2018</td>\n",
       "      <td>7201 Levander Loop in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Chihuahua Shorthair Mix</td>\n",
       "      <td>White/Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A821648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/16/2020 11:38:00 AM</td>\n",
       "      <td>Aug 2020</td>\n",
       "      <td>08/16/2019</td>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1 year</td>\n",
       "      <td>...</td>\n",
       "      <td>08/16/2020 10:10:00 AM</td>\n",
       "      <td>August 2020</td>\n",
       "      <td>Armadillo Rd And Clubway Ln in Austin (TX)</td>\n",
       "      <td>Wildlife</td>\n",
       "      <td>Sick</td>\n",
       "      <td>Other</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Raccoon</td>\n",
       "      <td>Gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A720371</td>\n",
       "      <td>Moose</td>\n",
       "      <td>02/13/2016 05:59:00 PM</td>\n",
       "      <td>Feb 2016</td>\n",
       "      <td>10/08/2015</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>...</td>\n",
       "      <td>02/08/2016 11:05:00 AM</td>\n",
       "      <td>February 2016</td>\n",
       "      <td>Dove Dr And E Stassney in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>Anatol Shepherd/Labrador Retriever</td>\n",
       "      <td>Buff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A720371</td>\n",
       "      <td>Moose</td>\n",
       "      <td>02/13/2016 05:59:00 PM</td>\n",
       "      <td>Feb 2016</td>\n",
       "      <td>10/08/2015</td>\n",
       "      <td>Adoption</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>...</td>\n",
       "      <td>02/15/2016 10:37:00 AM</td>\n",
       "      <td>February 2016</td>\n",
       "      <td>Austin (TX)</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>Anatol Shepherd/Labrador Retriever</td>\n",
       "      <td>Buff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal ID Name_x              DateTime_x MonthYear_x Date of Birth  \\\n",
       "0   A794011  Chunk  05/08/2019 06:20:00 PM    May 2019    05/02/2017   \n",
       "1   A776359  Gizmo  07/18/2018 04:02:00 PM    Jul 2018    07/12/2017   \n",
       "2   A821648    NaN  08/16/2020 11:38:00 AM    Aug 2020    08/16/2019   \n",
       "3   A720371  Moose  02/13/2016 05:59:00 PM    Feb 2016    10/08/2015   \n",
       "4   A720371  Moose  02/13/2016 05:59:00 PM    Feb 2016    10/08/2015   \n",
       "\n",
       "  Outcome Type Outcome Subtype Animal Type_x Sex upon Outcome  \\\n",
       "0    Rto-Adopt             NaN           Cat    Neutered Male   \n",
       "1     Adoption             NaN           Dog    Neutered Male   \n",
       "2   Euthanasia             NaN         Other          Unknown   \n",
       "3     Adoption             NaN           Dog    Neutered Male   \n",
       "4     Adoption             NaN           Dog    Neutered Male   \n",
       "\n",
       "  Age upon Outcome  ...              DateTime_y    MonthYear_y  \\\n",
       "0          2 years  ...  05/02/2019 04:51:00 PM       May 2019   \n",
       "1           1 year  ...  07/12/2018 12:46:00 PM      July 2018   \n",
       "2           1 year  ...  08/16/2020 10:10:00 AM    August 2020   \n",
       "3         4 months  ...  02/08/2016 11:05:00 AM  February 2016   \n",
       "4         4 months  ...  02/15/2016 10:37:00 AM  February 2016   \n",
       "\n",
       "                               Found Location      Intake Type  \\\n",
       "0                                 Austin (TX)  Owner Surrender   \n",
       "1           7201 Levander Loop in Austin (TX)            Stray   \n",
       "2  Armadillo Rd And Clubway Ln in Austin (TX)         Wildlife   \n",
       "3       Dove Dr And E Stassney in Austin (TX)            Stray   \n",
       "4                                 Austin (TX)  Owner Surrender   \n",
       "\n",
       "  Intake Condition Animal Type_y Sex upon Intake Age upon Intake  \\\n",
       "0           Normal           Cat   Neutered Male         2 years   \n",
       "1           Normal           Dog     Intact Male          1 year   \n",
       "2             Sick         Other         Unknown          1 year   \n",
       "3           Normal           Dog     Intact Male        4 months   \n",
       "4           Normal           Dog   Neutered Male        4 months   \n",
       "\n",
       "                              Breed_y            Color_y  \n",
       "0              Domestic Shorthair Mix  Brown Tabby/White  \n",
       "1             Chihuahua Shorthair Mix        White/Brown  \n",
       "2                             Raccoon               Gray  \n",
       "3  Anatol Shepherd/Labrador Retriever               Buff  \n",
       "4  Anatol Shepherd/Labrador Retriever               Buff  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intakes = pd.read_csv('Austin_Animal_Center_Intakes.csv')\n",
    "outcomes = pd.read_csv('Austin_Animal_Center_Outcomes.csv')\n",
    "df = outcomes.merge(intakes, how='left', on='Animal ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>MonthYear</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Outcome Subtype</th>\n",
       "      <th>Animal Type</th>\n",
       "      <th>Sex upon Outcome</th>\n",
       "      <th>Age upon Outcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Animal ID, Name, DateTime, MonthYear, Date of Birth, Outcome Type, Outcome Subtype, Animal Type, Sex upon Outcome, Age upon Outcome, Breed, Color]\n",
       "Index: []"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes[outcomes['Animal ID'] == 'Burrito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPq5Tto7BPzo",
    "outputId": "1551c918-bc8c-46b5-d3db-a97697d81b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Animal ID', 'Name_x', 'DateTime_x', 'MonthYear_x', 'Date of Birth',\n",
       "       'Outcome Type', 'Outcome Subtype', 'Animal Type_x', 'Sex upon Outcome',\n",
       "       'Age upon Outcome', 'Breed_x', 'Color_x', 'Name_y', 'DateTime_y',\n",
       "       'MonthYear_y', 'Found Location', 'Intake Type', 'Intake Condition',\n",
       "       'Animal Type_y', 'Sex upon Intake', 'Age upon Intake', 'Breed_y',\n",
       "       'Color_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "6lersMbauiVf",
    "outputId": "5292a566-6bef-47a9-df9d-4e69b1a60391"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rto-Adopt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Euthanasia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202369</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202370</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202371</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202372</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202373</th>\n",
       "      <td>Adoption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202374 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Outcome Type  y\n",
       "0         Rto-Adopt  1\n",
       "1          Adoption  1\n",
       "2        Euthanasia  0\n",
       "3          Adoption  1\n",
       "4          Adoption  1\n",
       "...             ... ..\n",
       "202369     Adoption  1\n",
       "202370     Adoption  1\n",
       "202371     Adoption  1\n",
       "202372     Adoption  1\n",
       "202373     Adoption  1\n",
       "\n",
       "[202374 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'] = ((df['Outcome Type'] == 'Adoption') | (df['Outcome Type'] == 'Rto-Adopt'))\n",
    "df.y = df.y.astype(int)\n",
    "df[['Outcome Type','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cpBQLBLiyS7W"
   },
   "outputs": [],
   "source": [
    "df.drop(['Name_x', 'Name_y','Outcome Subtype'], axis=1, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z9EH2mfeyGzt",
    "outputId": "cd2bbdb4-70dc-4cc2-a084-6a63adebf60a"
   },
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ICAZqZouv_f6"
   },
   "outputs": [],
   "source": [
    "def age_in_months(age_str):\n",
    "  split = age_str.split(' ')\n",
    "  label = split[1]\n",
    "  age = int(split[0])\n",
    "  if label == 'year' or label == 'years':\n",
    "    age *= 365\n",
    "  elif label == 'week' or label == 'weeks':\n",
    "    age *= 7\n",
    "  elif label == 'month' or label == 'months':\n",
    "    age *= 30\n",
    "  return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "4Tnp97MIxpOF"
   },
   "outputs": [],
   "source": [
    "df['Age upon Intake'] = df['Age upon Intake'].apply(lambda x: age_in_months(x))\n",
    "df['Age upon Outcome'] = df['Age upon Outcome'].apply(lambda x: age_in_months(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "nslBI7XeyxH-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/9w735kj12jbd75x2pmhw03d00000gn/T/ipykernel_17498/1141793705.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.DateTime_x = pd.to_datetime(df.DateTime_x)\n",
      "/var/folders/2c/9w735kj12jbd75x2pmhw03d00000gn/T/ipykernel_17498/1141793705.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df.DateTime_y = pd.to_datetime(df.DateTime_y)\n"
     ]
    }
   ],
   "source": [
    "df.DateTime_x = pd.to_datetime(df.DateTime_x)\n",
    "df.DateTime_y = pd.to_datetime(df.DateTime_y)\n",
    "df['Time_in_shelter'] = df.DateTime_x - df.DateTime_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OX9ZjBOyzAh9"
   },
   "outputs": [],
   "source": [
    "df.Time_in_shelter = df.Time_in_shelter.astype(int) / 60000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "whEGQHqR1rG-"
   },
   "outputs": [],
   "source": [
    "def get_fixed_status(input_str):\n",
    "  status = input_str.split(' ')[0]\n",
    "  return 1 if status == 'Neutered' or status == 'Spayed' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "POrAVXI12a0p"
   },
   "outputs": [],
   "source": [
    "def get_gender(input_str):\n",
    "  split = input_str.split(' ')\n",
    "  if len(split) < 2:\n",
    "    return 'unknown'\n",
    "  else:\n",
    "    return split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nahc5M8C2HTo"
   },
   "outputs": [],
   "source": [
    "df['Is_fixed'] = df['Sex upon Outcome'].apply(lambda x: get_fixed_status(x))\n",
    "df['Gender'] = df['Sex upon Outcome'].apply(lambda x: get_gender(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSAj-xJ84a-o",
    "outputId": "3b97ed4f-da03-4e52-bebb-620431cf1301",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Domestic Shorthair', 'Chihuahua Shorthair', 'Raccoon',\n",
       "       'Anatol Shepherd', 'American Foxhound', 'Border Collie',\n",
       "       'Pit Bull', 'Domestic Medium Hair', 'Opossum', 'Weimaraner', 'Bat',\n",
       "       'Yorkshire Terrier', 'Jack Russell Terrier', 'Great Pyrenees',\n",
       "       'Australian Cattle Dog', 'Beagle', 'Labrador Retriever',\n",
       "       'German Shepherd', 'Staffordshire', 'Dogo Argentino',\n",
       "       'Black Mouth Cur', 'Collie Rough', 'Polish', 'Rat Terrier',\n",
       "       'Doberman Pinsch', 'American Staffordshire Terrier',\n",
       "       'Miniature Poodle', 'Dachshund', 'Standard Schnauzer', 'Pug',\n",
       "       'American Bulldog', 'American Pit Bull Terrier', 'Siberian Husky',\n",
       "       'Australian Kelpie', 'Miniature Schnauzer', 'Miniature Pinscher',\n",
       "       'Boxer', 'Catahoula', 'Standard Poodle', 'Siamese',\n",
       "       'Queensland Heeler', 'Border Terrier', 'Flat Coat Retriever',\n",
       "       'Mastiff', 'Cairn Terrier', 'American Eskimo', 'Boston Terrier',\n",
       "       'Vizsla', 'Guinea Pig', 'Shiba Inu', 'Rabbit Sh', 'Rottweiler',\n",
       "       'Akita', 'Australian Shepherd', 'Plott Hound', 'Persian',\n",
       "       'Chicken', 'English Bulldog', 'Chihuahua Longhair', 'Harrier',\n",
       "       'Dachshund Wirehair', 'Cardigan Welsh Corgi', 'Lhasa Apso',\n",
       "       'Silky Terrier', 'Domestic Longhair', 'Havanese',\n",
       "       'Golden Retriever', 'Wire Hair Fox Terrier', 'Chow Chow',\n",
       "       'Great Dane', 'Greyhound', 'Collie Smooth', 'Norfolk Terrier',\n",
       "       'Basset Hound', 'Snowshoe', 'Bullmastiff',\n",
       "       'Treeing Walker Coonhound', 'Tibetan Spaniel', 'Bloodhound',\n",
       "       'Ferret', 'Schnauzer Giant', 'Belgian Malinois', 'Pointer',\n",
       "       'Bombay', 'Carolina Dog', 'Shih Tzu', 'Chinchilla', 'Dalmatian',\n",
       "       'Dogue De Bordeaux', 'Parakeet', 'Bluetick Hound', 'Schipperke',\n",
       "       'Welsh Terrier', 'Pomeranian', 'Italian Greyhound',\n",
       "       'Alaskan Malamute', 'Russian Blue', 'Whippet', 'Fox', 'Pekingese',\n",
       "       'Cavalier Span', 'Blue Lacy', 'American Shorthair', 'Pbgv',\n",
       "       'Brittany', 'Bernese Mountain Dog', 'Quaker', 'Bulldog', 'Snake',\n",
       "       'West Highland', 'Basenji', 'Bichon Frise', 'Podengo Pequeno',\n",
       "       'Parson Russell Terrier', 'Hamster', 'Squirrel',\n",
       "       'Munchkin Shorthair', 'Irish Setter', 'Alaskan Husky',\n",
       "       'Chinese Sharpei', 'Maltese', 'English Shepherd', 'Papillon',\n",
       "       'German Wirehaired Pointer', 'Bull Terrier', 'Bearded Collie',\n",
       "       'Skunk', 'French Bulldog', 'Cocker Spaniel', 'Ringtail',\n",
       "       'Finnish Spitz', 'Rat', 'Bengal', 'Pembroke Welsh Corgi',\n",
       "       'Manchester Terrier', 'Norwegian Elkhound',\n",
       "       'Soft Coated Wheaten Terrier', 'Leonberger', 'Lizard',\n",
       "       'English Coonhound', 'Californian', 'Manx', 'Bruss Griffon',\n",
       "       'Mexican Hairless', 'Rhod Ridgeback', 'Otterhound',\n",
       "       'Dutch Shepherd', 'English Pointer', 'Dove', 'Angora', 'Lionhead',\n",
       "       'Toy Poodle', 'Dachshund Longhair', 'St. Bernard Rough Coat',\n",
       "       'Pig', 'Peafowl', 'Nova Scotia Duck Tolling Retriever',\n",
       "       'Norwich Terrier', 'Maine Coon', 'Tibetan Terrier',\n",
       "       'Bull Terrier Miniature', 'German Shorthair Pointer', 'Himalayan',\n",
       "       'Black', 'Duck', 'Dutch', 'Toy Fox Terrier', 'Landseer',\n",
       "       'Redbone Hound', 'Shetland Sheepdog', 'Mouse',\n",
       "       'Australian Terrier', 'Ibizan Hound', 'Canaan Dog', 'Jindo',\n",
       "       'Chesa Bay Retr', 'Pigeon', 'Greater Swiss Mountain Dog',\n",
       "       'Angora-French', 'Picardy Sheepdog', 'Irish Terrier',\n",
       "       'Skye Terrier', 'Cane Corso', 'Belgian Sheepdog', 'Newfoundland',\n",
       "       'Heron', 'Wirehaired Pointing Griffon', 'St. Bernard Smooth Coat',\n",
       "       'Feist', 'Cold Water', 'Boykin Span', 'Japanese Bobtail', 'Goose',\n",
       "       'Lop-Holland', 'Hovawart', 'Angora-Satin', 'Beauceron',\n",
       "       'Airedale Terrier', 'Lop-English', 'Bantam', 'Rex', 'Rhinelander',\n",
       "       'Grackle', 'Scottish Terrier', 'German Pinscher', 'Havana',\n",
       "       'Patterdale Terr', 'Hedgehog', 'Canary', 'New Zealand Wht',\n",
       "       'Turkish Angora', 'Pharaoh Hound', 'Devon Rex',\n",
       "       'Smooth Fox Terrier', 'Netherlnd Dwarf', 'Wirehaired Vizsla',\n",
       "       'Ragdoll', 'British Shorthair', 'Tortoise', 'Tonkinese',\n",
       "       'Old English Bulldog', 'Boerboel', 'English Cocker Spaniel',\n",
       "       'Abyssinian', 'Hawk', 'Treeing Cur', 'Glen Of Imaal', 'Conure',\n",
       "       'Akbash', 'Chinese Crested', 'Scottish Fold', 'Hotot', 'Lowchen',\n",
       "       'Belgian Tervuren', 'Orpington', 'Norwegian Forest Cat', 'Pygmy',\n",
       "       'Budgerigar', 'Cornish Rex', 'Guinea', 'English Springer Spaniel',\n",
       "       'Affenpinscher', 'English Spot', 'Chickadee', 'Field Spaniel',\n",
       "       'Rabbit Lh', 'Macaw', 'Finch', 'Parrot', 'Other Bird', 'Armadillo',\n",
       "       'Cockatiel', 'Sparrow', 'American Curl Shorthair', 'Kuvasz',\n",
       "       'Potbelly Pig', 'Presa Canario', 'Turtle', 'Port Water Dog',\n",
       "       'Mockingbird', 'Keeshond', 'Burmese', 'Oriental Sh', 'Cymric',\n",
       "       'Coton De Tulear', 'Welsh Springer Spaniel', 'Balinese',\n",
       "       'Irish Wolfhound', 'Swedish Vallhund', 'Neapolitan Mastiff', 'Owl',\n",
       "       'Clumber Spaniel', 'Bedlington Terr', 'Saluki', 'Cinnamon',\n",
       "       'Rhode Island', 'Samoyed', 'Birman', 'Bluebird', 'Cardinal',\n",
       "       'Old English Sheepdog', 'Coyote', 'Gerbil', 'Bunting',\n",
       "       'Colorpoint', 'Wolf Hybrid', 'English Setter', 'Tibetan Mastiff',\n",
       "       'Turkish Van', 'Turkey', 'American', 'American Wirehair',\n",
       "       'Exotic Shorthair', 'Treeing Tennesse Brindle',\n",
       "       'Spanish Water Dog', 'Tarantula', 'Afghan Hound', 'Sussex Span',\n",
       "       'Falcon', 'Swiss Hound', 'English Foxhound', 'Crow',\n",
       "       'Japanese Chin', 'Lop-Amer Fuzzy', 'Lop-Mini', 'Cottontail',\n",
       "       'Kangal', 'Lovebird', 'Dandie Dinmont', 'Checkered Giant',\n",
       "       'Sphynx', 'American Sable', 'Eng Toy Spaniel', 'Flemish Giant',\n",
       "       'Lakeland Terrier', 'Spanish Mastiff', 'Quail', 'Silkie',\n",
       "       'Vulture', 'Tropical', 'Chinchilla-Amer', 'Briard', 'Hermit Crab',\n",
       "       'Harlequin', 'Munchkin Longhair', 'Havana Brown',\n",
       "       'Chinchilla-Stnd', 'Unknown', 'Rex-Mini', 'Pheasant', 'Chartreux',\n",
       "       'Jersey Wooly', 'Barred Rock', 'Spinone Italiano',\n",
       "       'Pixiebob Shorthair', 'Silver', 'Gordon Setter', 'Muscovy',\n",
       "       'Otter', 'Ocicat', 'Alaskan Klee Kai', 'Deer', 'Nuthatch',\n",
       "       'Britannia Petit', 'Waxwing', 'Sugar Glider', 'Borzoi', 'Cockatoo',\n",
       "       'Grand Basset Griffon Vendeen', 'Warbler', 'Beveren',\n",
       "       'Dwarf Hotot', 'Entlebucher', 'Lark', 'Goat', 'Dutch Sheepdog',\n",
       "       'Javanese', 'Angora-English', 'Bernese Hound', 'African',\n",
       "       'Belgian Hare', 'Starling', 'Sealyham Terr', 'Song Bird', 'Wren',\n",
       "       'Catbird', 'Whimbrel', 'Dachshund Stan', 'Bouv Flandres',\n",
       "       'Prairie Dog', 'Gamefowl', 'Bobcat', 'Leghorn', 'Frog', 'Sheep',\n",
       "       'Australorp', 'Egyptian', 'Florida White', 'Scottish Deerhound',\n",
       "       'Savannah'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Primary_breed'] = df['Breed_x'].apply(lambda x: x.split('/')[0].replace(' Mix', ''))\n",
    "df.Primary_breed.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Primary_color'] = df.Color_x.apply(lambda x: x.split('/')[0].split(' ')[0])\n",
    "df['Secondary_color'] = df.Color_x.apply(lambda x: 'N/A' if '/' not in x else x.split('/')[1].split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         0\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "202369    0\n",
       "202370    1\n",
       "202371    1\n",
       "202372    1\n",
       "202373    1\n",
       "Name: Normal_condition, Length: 201511, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Normal_condition'] = df['Intake Condition'].apply(lambda x: 1 if x == 'Normal' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Animal Type_x'] == 'Dog') | (df['Animal Type_x'] == 'Cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "3jhkEqD9vOTm"
   },
   "outputs": [],
   "source": [
    "X = df[['Primary_color', 'Secondary_color', 'Age upon Outcome', 'Age upon Intake', 'Is_fixed', 'Gender', 'Primary_breed', 'Time_in_shelter', 'Animal Type_x', 'Normal_condition']]\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Normal_condition'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5CRyYoC4aHX",
    "outputId": "ec3ff8fe-66f6-470d-a5bd-dfe06d3f46b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age upon Outcome', 'Age upon Intake', 'Is_fixed', 'Time_in_shelter',\n",
       "       'Normal_condition', 'Primary_color_Agouti', 'Primary_color_Apricot',\n",
       "       'Primary_color_Black', 'Primary_color_Blue', 'Primary_color_Brown',\n",
       "       ...\n",
       "       'Primary_breed_Welsh Terrier', 'Primary_breed_West Highland',\n",
       "       'Primary_breed_Whippet', 'Primary_breed_Wire Hair Fox Terrier',\n",
       "       'Primary_breed_Wirehaired Pointing Griffon',\n",
       "       'Primary_breed_Wirehaired Vizsla', 'Primary_breed_Wolf Hybrid',\n",
       "       'Primary_breed_Yorkshire Terrier', 'Animal Type_x_Cat',\n",
       "       'Animal Type_x_Dog'],\n",
       "      dtype='object', length=318)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe = pd.get_dummies(X)\n",
    "X_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "ij4rmg4rVMp2"
   },
   "outputs": [],
   "source": [
    "X_ohe.to_csv('X.csv')\n",
    "y.to_csv('y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "agaE3unWla3S"
   },
   "outputs": [],
   "source": [
    "X_ohe = pd.read_csv('X.csv', index_col=0)\n",
    "y = pd.read_csv('y.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "1o0b-54DmJiB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189044, 319)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.concat([X_ohe, y], axis=1).drop_duplicates()\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_data.sample(frac=.1, axis=0)\n",
    "train = pd.concat([all_data,test]).drop_duplicates(keep=False)\n",
    "\n",
    "y_train = train['y']\n",
    "X_train = train.drop(['y'], axis=1)\n",
    "\n",
    "y_test = test['y']\n",
    "X_test = test.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "LQaC6v2i7rWP"
   },
   "outputs": [],
   "source": [
    "auc_scorer = make_scorer(roc_auc_score)\n",
    "def auc_cv(model):\n",
    "    auc = cross_val_score(model, X_train, y_train, scoring=auc_scorer, cv = 5)\n",
    "    return(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "2nWi-8VG8L7I",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/yoav/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'auc')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABl+klEQVR4nO3deXxTZdo//k+SNumW7i1t6Qot+75a2gIqihuKOqg8KJvLb2bAEZf5zjDOKPigOPo44oyKOgqMowzjBo4LIDqytBRkK0sRaKGlBVpK93RL0+T8/khP2kDTNclJTj7v1ysv7cnpOXdCoFfv+7ruSyEIggAiIiIimVBKPQAiIiIie2JwQ0RERLLC4IaIiIhkhcENERERyQqDGyIiIpIVBjdEREQkKwxuiIiISFYY3BAREZGsMLghIiIiWWFwQx5rw4YNUCgUKCwsdNg9CgsLoVAosGHDBrtcb+fOnVAoFNi5c6ddrueJpk+fjunTp0s9DLtQKBRYsWKF5euefKYTExOxcOFCu45n4cKFSExMtOs1iXqDwQ2RC3r77bftFhCR9H7zm99AoVAgPz/f5jnPPvssFAoFjh075sSR9dylS5ewYsUK5OTkSD0UIpsY3BA5UEJCAhobG/HQQw/16PtsBTdTp05FY2Mjpk6daqcRep7vvvsO3333nVPvOW/ePADAxo0bbZ7zr3/9CyNHjsSoUaN6fZ+HHnoIjY2NSEhI6PU1unLp0iWsXLmyw+Dm73//O06fPu2wexN1F4MbIgdSKBTw8fGBSqWyy/WUSiV8fHygVDrmr259fb1DrtuRlpYWNDc3O+1+IrVaDbVa7dR7Tp48GcnJyfjXv/7V4fPZ2dkoKCiwBEG9pVKp4OPjA4VC0afr9Ja3tzc0Go0k9yZqj8EN0VXefvttDB8+HBqNBjExMViyZAmqq6uvOe+tt97CgAED4Ovri0mTJmHPnj3X5HN0lHNTWlqKRYsWITY2FhqNBtHR0bjrrrsseRKJiYnIzc3Frl27oFAooFAoLNe0lXOzf/9+3HbbbQgJCYG/vz9GjRqFN954o9PXKeZn7Nq1C7/+9a8RGRmJ2NhYy/Nbt25FRkYG/P39odVqcfvttyM3N/ea63z66acYNmwYfHx8MGLECGzevPma3Avxffi///s/rFmzBgMHDoRGo8HJkycBAKdOncIvfvELhIaGwsfHBxMmTMB//vMfq/sYDAasXLkSKSkp8PHxQVhYGNLT07Fjx45uv7dAxzk3ZWVlePjhh9GvXz/4+Phg9OjR+Mc//mF1TvvX8N5771lew8SJE3HgwIFO32vAPHtz6tQpHD58+JrnNm7cCIVCgblz56K5uRnPPfccxo8fj6CgIPj7+yMjIwM//vhjl/foKOdGEASsWrUKsbGx8PPzw/XXX9/hn2NlZSWeeeYZjBw5EgEBAQgMDMStt96Ko0ePWs7ZuXMnJk6cCABYtGiR5fMpfr47yrmpr6/H008/jbi4OGg0GgwePBj/93//B0EQrM5TKBRYunQptmzZghEjRkCj0WD48OHYtm1bl6+b6GpeUg+AyJWsWLECK1euxIwZM/CrX/0Kp0+fxtq1a3HgwAFkZWXB29sbALB27VosXboUGRkZePLJJ1FYWIjZs2cjJCTEKkDoyL333ovc3Fw8/vjjSExMRFlZGXbs2IGioiIkJiZizZo1ePzxxxEQEIBnn30WANCvXz+b19uxYwfuuOMOREdH44knnkBUVBR+/vlnfP3113jiiSe6fM2//vWvERERgeeee84yc/PPf/4TCxYswMyZM/HnP/8ZDQ0NWLt2LdLT03HkyBHLD7BvvvkG999/P0aOHInVq1ejqqoKDz/8MPr379/hvdavX4+mpiY89thj0Gg0CA0NRW5uLtLS0tC/f3/8/ve/h7+/Pz755BPMnj0bn3/+Oe6++27Ln83q1avxyCOPYNKkSaitrcXBgwdx+PBh3HTTTd16bzvS2NiI6dOnIz8/H0uXLkVSUhI+/fRTLFy4ENXV1de8hxs3boROp8P/9//9f1AoFHjllVdwzz334Ny5c5bPR0fmzZuHlStXYuPGjRg3bpzluNFoxCeffIKMjAzEx8ejvLwc77//PubOnYtHH30UOp0OH3zwAWbOnImffvoJY8aM6fLPtL3nnnsOq1atwm233YbbbrsNhw8fxs0333zNrNm5c+ewZcsWzJkzB0lJSbh8+TLeffddTJs2DSdPnkRMTAyGDh2KF154Ac899xwee+wxZGRkAACmTJnS4b0FQcCdd96JH3/8EQ8//DDGjBmD7du347e//S0uXryI119/3er8zMxMfPHFF/j1r38NrVaLv/71r7j33ntRVFSEsLCwHr1u8nACkYdav369AEAoKCgQBEEQysrKBLVaLdx8882C0Wi0nPfmm28KAIR169YJgiAIer1eCAsLEyZOnCgYDAbLeRs2bBAACNOmTbMcKygoEAAI69evFwRBEKqqqgQAwquvvtrp2IYPH251HdGPP/4oABB+/PFHQRAEoaWlRUhKShISEhKEqqoqq3NNJlO3Xn96errQ0tJiOa7T6YTg4GDh0UcftTq/tLRUCAoKsjo+cuRIITY2VtDpdJZjO3fuFAAICQkJlmPi+xAYGCiUlZVZXffGG28URo4cKTQ1NVmNfcqUKUJKSorl2OjRo4Xbb7/d5uvp7ns7bdo0q/d2zZo1AgDho48+shxrbm4WUlNThYCAAKG2ttbqNYSFhQmVlZWWc7/88ksBgPDVV191el9BEISJEycKsbGxVp+vbdu2CQCEd999VxAE85+pXq+/5rX169dPWLx4sdVxAMLzzz9v+drWZ/r222+3+jz84Q9/EAAICxYssBxramqyGpf4mjUajfDCCy9Yjh04cMDqM93eggULrP7ct2zZIgAQVq1aZXXeL37xC0GhUAj5+flWr0WtVlsdO3r0qABA+Nvf/nbNvYg6w2Upolbff/89mpubsWzZMquclkcffRSBgYH45ptvAAAHDx5ERUUFHn30UXh5tU1+zps3DyEhIZ3ew9fXF2q1Gjt37kRVVVWfx3zkyBEUFBRg2bJlCA4Otnquu3kXjz76qFVO0I4dO1BdXY25c+eivLzc8lCpVJg8ebJleeTSpUs4fvw45s+fj4CAAMv3T5s2DSNHjuzwXvfeey8iIiIsX1dWVuK///0v7rvvPuh0Osu9KioqMHPmTOTl5eHixYsAgODgYOTm5iIvL6/Da/f2vf32228RFRWFuXPnWo55e3vjN7/5Derq6rBr1y6r8++//36rP2dx9uLcuXNd3uvBBx/EhQsXsHv3bsuxjRs3Qq1WY86cOQDMeTNiTpDJZEJlZSVaWlowYcKEDpe0OiN+ph9//HGrz8OyZcuuOVej0Vg+90ajERUVFQgICMDgwYN7fF/Rt99+C5VKhd/85jdWx59++mkIgoCtW7daHZ8xYwYGDhxo+XrUqFEIDAzs1ntL1J5HBze7d+/GrFmzEBMTA4VCgS1btjj0fitWrLCsUYuPIUOG9Pp6Yg7A1Y99+/Z1+b0bNmzAqFGj4OPjg8jISCxZssTq+WPHjiEjIwM+Pj6Ii4vDK6+8YvV8bm4u7r33XiQmJkKhUGDNmjW9fh3d5eh7nj9/HgAwePBgq+NqtRoDBgywPC/+Nzk52eo8Ly+vLvf40Gg0+POf/4ytW7eiX79+mDp1Kl555RWUlpb2asxnz54FAIwYMaJX3w8ASUlJVl+LwcMNN9yAiIgIq8d3332HsrIyALbfB1vHOrpXfn4+BEHAn/70p2vu9fzzzwOA5X4vvPACqqurMWjQIIwcORK//e1vrcqme/venj9/HikpKdckaQ8dOtTqdYri4+OtvhYDne4EVA888ABUKpWlaqqpqQmbN2/GrbfeahUw/eMf/7D8/QwLC0NERAS++eYb1NTUdHmPq18bAKSkpFgdj4iIuCYQN5lMeP3115GSkgKNRoPw8HBERETg2LFjPb5v+/vHxMRAq9VaHe/uewuY3197/CJAnsWjg5v6+nqMHj0ab731ltPuOXz4cJSUlFgemZmZnZ7fnQ25vv/+e6trjh8/vtPz//KXv+DZZ5/F73//e+Tm5uL777/HzJkzLc/X1tbi5ptvRkJCAg4dOoRXX30VK1aswHvvvWc5p6GhAQMGDMDLL7+MqKiorl+4HUhxT0dYtmwZzpw5g9WrV8PHxwd/+tOfMHToUBw5ckSS8fj6+lp9bTKZAJjzbnbs2HHN48svv7T7vZ555pkO77Vjxw5LoDR16lScPXsW69atw4gRI/D+++9j3LhxeP/99y3Xc8Z7a6vyTbgqQbYjkZGRuOmmm/D555/DYDDgq6++gk6ns6qS+uijj7Bw4UIMHDgQH3zwAbZt24YdO3bghhtusLxfjvDSSy/hqaeewtSpU/HRRx9h+/bt2LFjB4YPH+7Q+7bXl/eWqD2PTii+9dZbceutt9p8Xq/X49lnn8W//vUvVFdXY8SIEfjzn//cp91Nvby87P6DOSwsrNvXrKqqwh//+Ed89dVXuPHGGy3H2++t8fHHH6O5uRnr1q2DWq3G8OHDkZOTg7/85S947LHHAAATJ060VE38/ve/7/BeJpMJf/7zn/Hee++htLQUgwYNwp/+9Cf84he/6NXr7M49+0LcG+T06dMYMGCA5XhzczMKCgowY8YMq/Py8/Nx/fXXW85raWlBYWFht/YpGThwIJ5++mk8/fTTyMvLw5gxY/Daa6/ho48+AtD9JSVxCv/EiROW8fWVeM3IyMhOr9n+fbhaZ5vVtSe+z97e3t0af2hoKBYtWoRFixahrq4OU6dOxYoVK/DII49Yjb+z97aj13Hs2DGYTCar2ZtTp05ZvU57mTdvHrZt24atW7di48aNCAwMxKxZsyzPf/bZZxgwYAC++OILq8+BOJPVE+LY8/LyrD7TV65cuWY25LPPPsP111+PDz74wOp4dXU1wsPDLV/3pMw8ISEB33//PXQ6ndXsjaPeWyKRR8/cdGXp0qXIzs7Gpk2bcOzYMcyZMwe33HKLzTX/7sjLy0NMTAwGDBiAefPmoaioqM/jvPPOOxEZGYn09PRrymevtmPHDphMJly8eBFDhw5FbGws7rvvPhQXF1vOyc7OxtSpU632Apk5cyZOnz7do+nh1atX48MPP8Q777yD3NxcPPnkk3jwwQevyWFwFTNmzIBarcZf//pXq98UP/jgA9TU1OD2228HAEyYMAFhYWH4+9//jpaWFst5H3/8cZfvT0NDA5qamqyODRw4EFqtFnq93nLM39+/w/Lzq40bNw5JSUlYs2bNNef39rfdmTNnIjAwEC+99BIMBsM1z1+5cgUAEBMTgxEjRuDDDz9EXV2d5fldu3bh+PHj3bpXZGQkpk+fjnfffRclJSU27wUAFRUVVs8FBAQgOTnZ8r5197292m233YbS0lL8+9//thxraWnB3/72NwQEBGDatGndei3dNXv2bPj5+eHtt9/G1q1bcc8998DHx8fyvDh70f7Pb//+/cjOzu7xvWbMmAFvb2/87W9/s7peR0u6KpXqms/Mp59+asl5Evn7+wNAtz6ft912G4xGI958802r46+//joUCkWnv1wS9YVHz9x0pqioCOvXr0dRURFiYmIAmKfOt23bhvXr1+Oll17q8TUnT56MDRs2YPDgwSgpKcHKlSuRkZGBEydOXLMm3R0BAQF47bXXkJaWBqVSic8//xyzZ8/Gli1bcOedd3b4PefOnYPJZMJLL72EN954A0FBQfjjH/+Im266CceOHYNarUZpaek1uRFiKXJpaWmXSbOAedbrpZdewvfff4/U1FQA5t/SMzMzLeWlriYiIgLLly/HypUrccstt+DOO+/E6dOn8fbbb2PixIl48MEHAZhzcFasWIHHH38cN9xwA+677z4UFhZiw4YNGDhwYKe/2Z45cwY33ngj7rvvPgwbNgxeXl7YvHkzLl++jAceeMBy3vjx47F27VqsWrUKycnJiIyMxA033HDN9ZRKJdauXYtZs2ZhzJgxWLRoEaKjo3Hq1Cnk5uZi+/btPX4fAgMDsXbtWjz00EMYN24cHnjgAURERKCoqAjffPMN0tLSLD+sXnrpJdx1111IS0vDokWLUFVVhTfffBMjRoywCng689ZbbyE9PR0jR47Eo48+igEDBuDy5cvIzs7GhQsXLPusDBs2DNOnT8f48eMRGhqKgwcP4rPPPsPSpUt79N5e7bHHHsO7776LhQsX4tChQ0hMTMRnn32GrKwsrFmzpld/NzsTEBCA2bNnW/Jurt6474477sAXX3yBu+++G7fffjsKCgrwzjvvYNiwYd1+T0URERF45plnsHr1atxxxx247bbbcOTIEWzdutVqNka87wsvvIBFixZhypQpOH78OD7++GOrGR/AHDAGBwfjnXfegVarhb+/PyZPnnzNvxkAMGvWLFx//fV49tlnUVhYiNGjR+O7777Dl19+iWXLllklDxPZlWR1Wi4GgLB582bL119//bUAQPD397d6eHl5Cffdd58gCILw888/CwA6ffzud7+zec+qqiohMDBQeP/99y3HbrnlFqv7ARD8/PwsXw8bNqzT1/HQQw8J6enpNp9/8cUXBQDC9u3bLcfKysoEpVIpbNu2TRAEQbjpppuExx57zOr7cnNzBQDCyZMnr7lmQkKC8Prrr1sdO3HiRIfvn7e3tzBp0iRBEAShsbGxy/fv/vvv7/B1dHTPnrq6bFb05ptvCkOGDBG8vb2Ffv36Cb/61a+uKbMWBEH461//KiQkJAgajUaYNGmSkJWVJYwfP1645ZZbLOdcXQpeXl4uLFmyRBgyZIjg7+8vBAUFCZMnTxY++eQTq2uXlpYKt99+u6DVaq3Ky68uBRdlZmYKN910k6DVagV/f39h1KhRXZbPiq//wIEDHT7/448/CjNnzhSCgoIEHx8fYeDAgcLChQuFgwcPWp23adMmYciQIYJGoxFGjBgh/Oc//xHuvfdeYciQIde8D7bKtM+ePSvMnz9fiIqKEry9vYX+/fsLd9xxh/DZZ59Zzlm1apUwadIkITg4WPD19RWGDBkivPjii0Jzc3OP3turS8EFQRAuX74sLFq0SAgPDxfUarUwcuTIa0qdO3sNuKokuyvffPONAECIjo6+pvzaZDIJL730kuWzNXbsWOHrr7++psy6o/t29Jk2Go3CypUrhejoaMHX11eYPn26cOLECSEhIeGaUvCnn37acl5aWpqQnZ3d4fv15ZdfCsOGDRO8vLysPt8djVGn0wlPPvmkEBMTI3h7ewspKSnCq6++es1WBQCEJUuWXPNeXT1Oou5QCAIztQDzOvLmzZsxe/ZsAMC///1vzJs3D7m5udckuQUEBCAqKgrNzc1dliiKlQ62TJw4ETNmzMDq1asBABcvXkRjY6Pl+ZSUFOzcudOyKZq3t3en69RvvfUWVq1a1eEUP2DeRG3x4sUoLi622myuX79+WLVqFR599FHMnz8ftbW1VtVjP/74I2644QZUVlZeM3OTmJiIZcuWWZWX7t+/H9ddd53V2EUajQZxcXEQBKHLPjSBgYGWmbOu7ik1k8mEiIgI3HPPPfj73/8u9XAkNWbMGERERFjtHkxE5CxclrJh7NixMBqNKCsrs+xjcTW1Wt2nUu66ujqcPXvWqqliRzu7JiQkdFliLMrJyUF0dLTN59PS0gCYk2bF4KayshLl5eWWoCk1NRXPPvssDAaDZcfVHTt2YPDgwd1akgLMSwgajQZFRUU2l6D6WgovpaamJmg0GqslqA8//BCVlZV9Sjh3NwaDAQqFwmq/n507d+Lo0aNYtWqVhCMjIk/m0cFNXV2dVVVHQUEBcnJyEBoaikGDBmHevHmYP38+XnvtNYwdOxZXrlzBDz/8gFGjRlmSS3vimWeewaxZs5CQkIBLly7h+eefh0qlsto8rCf+8Y9/QK1WY+zYsQCAL774AuvWrbMqjd28eTOWL19uqU4YNGgQ7rrrLjzxxBN47733EBgYiOXLl2PIkCGWyp//+Z//wcqVK/Hwww/jd7/7HU6cOIE33njDaqv05uZmS1+g5uZmXLx4ETk5OZYkT61Wi2eeeQZPPvkkTCYT0tPTUVNTg6ysLAQGBmLBggU9fr1d3dOZ9u3bhyeffBJz5sxBWFgYDh8+jA8++AAjRoywbMbmCS5evIgZM2bgwQcfRExMDE6dOoV33nkHUVFR+OUvfyn18IjIU0m8LCYpMX/h6oe4vtvc3Cw899xzQmJiouDt7S1ER0cLd999t3Ds2LFe3e/+++8XoqOjBbVaLfTv31+4//77rbYa7wg6yAkRbdiwQRg6dKjg5+cnBAYGCpMmTRI+/fRTq3PENfj2ampqhMWLFwvBwcFCaGiocPfddwtFRUVW5xw9elRIT08XNBqN0L9/f+Hll1+2el7MP7j60X5t3mQyCWvWrBEGDx4seHt7CxEREcLMmTOFXbt2dfFOdaw793SWgoICYdasWUK/fv0suTmLFi0SLl++7PSxSKm6ulq47777hP79+wtqtVoICQkRfvGLX3T5uSYiciTm3BAREZGscJ8bIiIikhUGN0RERCQrHpdQbDKZcOnSJWi12h5tI05ERETSEQQBOp0OMTEx1zS6vZrHBTeXLl1CXFyc1MMgIiKiXrh6n7aOeFxwI26lXlxcjMDAQIlHQ0RERN1RW1uLuLi4brVE8bjgRlyKCgwMZHBDRETkZrqTUsKEYiIiIpIVBjdEREQkKwxuiIiISFYY3BAREZGsMLghIiIiWWFwQ0RERLLC4IaIiIhkhcENERERyQqDGyIiIpIVBjdEREQkKwxuiIiISFYY3BAREZGsMLhxE43NRqmHQB5AEAQ0t5ikHgYRUZ8wuHEDu85cwbDnt+H9PeekHgrJ3KYDxRj0x63YcfKy1EMhIuo1BjduYHtuKQQBOFxUJfVQSOY2HSgGAPy79b9ERO6IwY0byCmqBgDomlqkHQjJWnVDM45dqAYA7DtXAYORy1NE5J4Y3Li4xmYjTl/WAQDq9AxuyHGy8isgCOb/r9O3IKe4WtLxEBH1FoMbF3fiUg2MJvNPnDrO3JADZeZfsfp6T165RCMhIuobBjcuTlySAjhzQ44jCAJ2nzEHM7eOiAIA7Mm70tm3EBG5LAY3Li6nNQcC4MwNOU5BeT0uVjdCrVLi6ZsHAwCOFlejptEg8ciIiHqOwY2Ls5q5aW6BqXWJisiexCWo8QkhSI4MwIAIf5gEIPtshcQjIyLqOQY3LuyKTo+L1Y2WrwUBaDBwMz+yP3EJKmNQuPm/yeFWx4mI3AmDGxd2tLVaJSUyACqlAgBQz7wbsjOD0WSZoZmaEgEAyGj9b2Y+k4qJyP0wuHFhYinumLhgBGi8AHCvG7K/I0XVqG82ItRfjWHRgQCA6waGwUupwPmKBhRVNEg8QiKinpE0uFm7di1GjRqFwMBABAYGIjU1FVu3brV5/oYNG6BQKKwePj4+Thyxcx1tTSYeE98W3LBiiuxNXHpKSw6HsnWGMEDjhXHxIebn87k0RUTuRdLgJjY2Fi+//DIOHTqEgwcP4oYbbsBdd92F3Nxcm98TGBiIkpISy+P8+fNOHLHzmEyCZeZmdGwwtD6twQ1nbsjOdrcmE2ekhFsdT2/9OpP73RCRm/GS8uazZs2y+vrFF1/E2rVrsW/fPgwfPrzD71EoFIiKinLG8CR1rrweuqYW+HgrMThK227mhqW5ZD/tWy50FNz8ZccZZOWXw2gSLHlfRESuzmVyboxGIzZt2oT6+nqkpqbaPK+urg4JCQmIi4vrcpYHAPR6PWpra60e7kBMJh4REwRvlRIBPsy5Ifvbe9bcciElMgDRQb5Wz43qH4RAHy/UNrVYAiAiIncgeXBz/PhxBAQEQKPR4Je//CU2b96MYcOGdXju4MGDsW7dOnz55Zf46KOPYDKZMGXKFFy4cMHm9VevXo2goCDLIy4uzlEvxa7aJxMDgD9zbsgBLCXgrdVR7XmplJgyUCwJ59IUEbkPyYObwYMHIycnB/v378evfvUrLFiwACdPnuzw3NTUVMyfPx9jxozBtGnT8MUXXyAiIgLvvvuuzesvX74cNTU1lkdxcbGjXopdWYKb+GAAgFbDnBuyr/YtF65ekhKJ+94w74aI3ImkOTcAoFarkZycDAAYP348Dhw4gDfeeKPTgEXk7e2NsWPHIj8/3+Y5Go0GGo3GbuN1hiaDET+XmJfPRscGA0Bbzk0zgxuyD7HlgrdKgckDQjs8JyPZPKNzuKgKdfoWy+eQiMiVST5zczWTyQS9Xt+tc41GI44fP47o6GgHj8q5ci/VosUkIDxAjdgQcx5EAKulyM7EpaYJCaHwU3cctMSH+SE+1A8tJgH72IqBiNyEpMHN8uXLsXv3bhQWFuL48eNYvnw5du7ciXnz5gEA5s+fj+XLl1vOf+GFF/Ddd9/h3LlzOHz4MB588EGcP38ejzzyiFQvwSGOtisBVyja9h0BmHND9iMGN+LSky3ikhV3KyYidyHpHHNZWRnmz5+PkpISBAUFYdSoUdi+fTtuuukmAEBRURGUyrb4q6qqCo8++ihKS0sREhKC8ePHY+/evTYTkN3V1cnEALjPDdmVueWCOViZ2kEycXsZKeH4eH8RdrPPFBG5CUmDmw8++KDT53fu3Gn19euvv47XX3/dgSNyDVcnEwNAgMYbAKDjzA3ZQUctF2xJHRgOpQI4d6Uel6obERPs2+n5RERSc7mcG09XWd+MokpzL59RrcnEAHNuyL46arlgS5CvN0a3ziKyaoqI3AGDGxcj5tsMiPBHkK+35XiARgWAOTdkH3tstFywJSPZfB6XpojIHTC4cTEd5dsAbctSDG6orzpruWBLxiBzXk5WfjlMJsFRQyMisgsGNy7GZnDDZSmyk71nK2Cy0XLBljFx5s70VQ0G5F5yjxYmROS5GNy4EEEQcLT1N+prZ27MwU2z0QR9i9HJIyM5EfNt0rs5awMA3iolrhsQZv7+fC5NEZFrY3DjQs5XNKC6wQC1lxJDoqwrWNrvDFuvZ3BDvdO+5UJXJeBXs+x3w6RiInJxDG5ciLgkNTwmEGov6z8alVIBP3VrUjGXpqiXCisaumy5YIsY3BwsrEJjMwNsInJdDG5ciK18G5E4e6PTG5w0IpIbcUmqs5YLtiSF+6N/sC+ajSbsL2ArBiJyXQxuXEiXwQ2TiqmPLF3Au2i50BGFQoH01pLwPVyaIiIXxuDGRehbjDjZWoXS1cwNy8GpN9q3XBC7ffeUGBQx74aIXBmDGxdxqkSHZqMJIX7eiA/16/AcBjfUF2LLhRA/bwyP6bzlgi1pA8OhUACnL+tQVttk5xESEdkHgxsXIS5JjY5r6wR+NUvODZelqBcyLSXgEV22XLAlxF+Nkf2DAHBpiohcF4MbF9FVvg3QlnNTz5kb6oXdPWy5YIuYd5OZz+CGiFwTgxsXcbTdzI0tWi5LUS/1puWCLeLmf3vyyiEIbMVARK6HwY0LqGkw4Fx5PQBgTLtO4FcTZ264LEU9JbZcSO5BywVbxieEwNdbhfI6PU6V6uw0QiIi+2Fw4wLElgsJYX4I8VfbPI/NM6m3xP1t+jprAwAaL5VlA0BWTRGRK2Jw4wK6k28DcJ8b6p2+tFywJaP1Orvz2GeKiFwPgxsX0N3ghjk31Bt9ablgizgD9FNBJZoMbMVARK6FwY3EBEHoVjIxAPhb2i8wuKHu60vLBVtSIgPQL1ADfYsJBwur7HJNIiJ7YXAjsQtVjaiob4a3SoFh0Z1vrGbZxK+JvaWo+8QlqXQ75NuIzK0YzEtTe/K5NEVEroXBjcTEJalh0YHw8VZ1eq7Wss8NlwGoewxGE/adMze5tFe+jUhcmmJSMRG5GgY3Esvp5pIUwPYL1HM5xdWo07f0qeWCLWmtm/nlXqpFeZ3ertcmIuoLBjcS624yMdCuWkrfApOJm6dR1/ac6XvLBVsitBoMbV1KzeJuxUTkQhjcSMhgNOHExRoAPZu5AYD6Zs7eUNcsLReS7Zdv015Gu92KiYhcBYMbCZ0u1UHfYkKgjxeSwvy7PF/jpYS3yvzbN5emqCvtWy7YM5m4vfZ5N2zFQESugsGNhNrn23RnyUChULSrmGJwQ51r33IhJrhvLRdsmZgYCrWXEqW1TTh7pc4h9yAi6ikGNxLqSb6NiHvdUHftsVMX8M74eKswOcm8MaBYck5EJDUGNxLqTXDDmRvqDnPLBXMysb1LwK+W3prPk8mkYiJyEQxuJFLbZLBM43cnmVik9WE5OHXNES0XbBHzefadq0Bzi8mh9yIi6g4GNxI5fqEGggDEhvgiPEDT7e/jXjfUHWLLhfEJIXZruWDL0KhAhAeo0dBsxOEitmIgIukxuJFIb5akACDAxxsAl6Woc235No5dkgIApVJh2dCPuxUTkStgcCORXgc3nLmhLhiMJmSfdUzLBVvEIEqcMSIikhKDGwkIgtDr4IY5N9QVR7ZcsEVMKj52sQbVDc1OuScRkS0MbiRQUtOEKzo9VEoFhscE9eh7xZkbHZelyAax5UJacrjdWy7YEhXkg5TIAAgCkJVf4ZR7EhHZwuBGAuKszZAoLXzVnXcCv5o/l6WoC2LLBWctSYnEpanMfC5NEZG0GNxIoLdLUgCgtexzY7DjiEguahoMDm+5YIu4WeDuM2zFQETSYnAjgfZtF3oqgDk31Im9Z8sd3nLBlskDQuGtUuBidSMKKxqcem8iovYY3DhZi9GE4xfMncDH9ia4sSxLGe05LJKJ3U5ouWCLn9oL4xNCAACZrJoiIgkxuHGyvLI6NBqMCNB4YUBEQI+/v23mhstSZK19ywUpghvzfc15N7u53w0RSYjBjZOJS1KjYoOg6kUli5a9pcgGq5YLSWGSjEEMqvadrUCLka0YiEgaDG6cLKeoGkDvkokB65wbJm1Se5ntWi6IVXXONjwmCMF+3tDpW3C0NbGZiMjZGNw4mfgPfm+SiYG2nBuDUYCeTQqpnd1ObLlgi6pdK4bdZ7g0RUTSYHDjRPX6Fpy5rAPQu2RiAPBv1wSRFVMkkqLlgi0ZYp+pfAY3RCQNBjdOdPxiDUwCEBPkg8hAn15dQ6lUwL914z/m3ZBIipYLtoj76+QUV6OW+zERkQQY3DhRX/a3aY973dDVpGi5YEtsiB8GhPvDaBIss0lERM7E4MaJ+ppMLGJ/KbrannxpWi7YIs7eZLIknIgkwODGifqaTCwK8PEGYM7hIappMOBo66ygs1su2CImNe/hZn5EJAEGN05yubYJJTVNUCqAkf171gn8alo2z6R2pGy5YMt1A0KhUipQWNGA4kq2YiAi52Jw4yRHWpekBvXT9nkPEsuyFIMbQlsJeHqya8zaAIDWx9tSEbiHS1NE5GQMbpxEXJLqa74N0C6hmDk3Hk8QBMvSz9RBrhPcAG1LU5n5XJoiIudicOMk9komBto3z2SZrac7X9GAC1XStlywRcz/ycqvgNHE3bSJyHkY3DiB0STg+EVzJ/C+JhMD7YIbztx4vD0u0HLBltGxQdD6eKGm0WD5/BMROQODGyc4e6UOdfoW+KlVGNRP2+frictSzLkhV2i5YIuXSokpA82zSZmsmiIiJ2Jw4wTiktTI/r3rBH41ztwQYN1yIcNFSsCvJgZdu5lUTEROxODGCXLsmEwMANrWmZv6ZgY3nuyoVcuFvm0v4Chi0HWkqIr7MhGR0zC4cQJ7JhMDnLkhM3E2JC053C4zgo6QEOaPuFBfGIwC9hewFQMROQeDGwdrbDbidGsncHskEwPc54bMLCXgLphv055laeoMl6aIyDkY3DjYiUs1MJoERGo1iA7qXSfwq3GfG3LFlgu2ZLRuLpiZz+CGiJyDwY2DtV+SUijss3Sg1Zh7S7H9gucSWy4MjPB3mZYLtkwZGA6lAsgvq0NJTaPUwyEiD8DgxsFy7NQssz1/jQoA0NBs5OZoHkrsAu6KJeBXC/LzxqjYYABsxUBEzsHgxsHEmZuxdgxuxGUpgLM3nkgQBOw+45otF2wRq6YyGdwQkRMwuHGgKzo9LlY3QqEARsbar1RX46WCWmX+o2Nw43lcueWCLW19psph4mwjETkYgxsHEhM+kyMCoPXxtuu1mVTsuVy55YItY+OD4a9WobK+GSdLaqUeDhHJHIMbB8ppDW7stb9Ne23NMxnceBpXbrlgi7dKidTWVgzMuyEiR2Nw40D5ZXUAgGExgXa/NoMbz2QwmrDPxVsu2JJuKQlnnykiciwGNw6k0xsAACF+artfm8tSnulocTV0Lt5ywZb01pmmA4VVaGw2SjwaIpIzBjcOJAYeAQ7Ii9BaZm4Mdr82uS53aLlgy8AIf8QE+aC5xYSfCiulHg4RyRiDGwcS2yO0L922F/GaOs7ceBQxmdjdlqQAQKFQWHZTzszj0hQROQ6DGwdy5MyNP3NuPI51ywX3SSZuT0yCZlIxETkSgxsHEgMPrQNmbrTsDO5xss+1tVzo7+ItF2xJSw6HQgGcKtWhTNck9XCISKYkDW7Wrl2LUaNGITAwEIGBgUhNTcXWrVs7/Z5PP/0UQ4YMgY+PD0aOHIlvv/3WSaPtGaNJQENr0qQjZm5YLeV53LEE/Gqh/moMb60ezGIjTSJyEEmDm9jYWLz88ss4dOgQDh48iBtuuAF33XUXcnNzOzx/7969mDt3Lh5++GEcOXIEs2fPxuzZs3HixAknj7xr9c1tQYcjc24Y3HgGd2y5YItlaeoMgxsicgxJg5tZs2bhtttuQ0pKCgYNGoQXX3wRAQEB2LdvX4fnv/HGG7jlllvw29/+FkOHDsX//u//Yty4cXjzzTedPPKuictFapUSGi+V3a/PmRvP4o4tF2zJaN3vZk9+OQSBrRiIyP5cJufGaDRi06ZNqK+vR2pqaofnZGdnY8aMGVbHZs6ciezsbJvX1ev1qK2ttXo4Q50DK6WAtjwe5tx4BrFKaly8+7RcsGV8Ygh8vJW4otPj9GWd1MMhIhmSPLg5fvw4AgICoNFo8Mtf/hKbN2/GsGHDOjy3tLQU/fr1szrWr18/lJaW2rz+6tWrERQUZHnExcXZdfy26BxYKWW+rrlXFWduPINYXTR1kPvm24g0XirL7BO7hBORI0ge3AwePBg5OTnYv38/fvWrX2HBggU4efKk3a6/fPly1NTUWB7FxcV2u3ZnLDM3jgpuuM+NxzAYTch205YLtoivgyXhROQIks9vq9VqJCcnAwDGjx+PAwcO4I033sC77757zblRUVG4fPmy1bHLly8jKirK5vU1Gg00Go19B90Njtzjxnxdcx4PZ27kz51bLthiTir+GfsLKtBkMMLH2/55aUTkuSSfubmayWSCXq/v8LnU1FT88MMPVsd27NhhM0dHSmJbBEfl3LRflmJSpryJJeBT3LDlgi2D+gUgUqtBk8GEw+erpB4OEcmMpMHN8uXLsXv3bhQWFuL48eNYvnw5du7ciXnz5gEA5s+fj+XLl1vOf+KJJ7Bt2za89tprOHXqFFasWIGDBw9i6dKlUr0Emxyec9MaNBlNApoMJofcg1yDmEw8VSZLUoB1K4bdXJoiIjuTNLgpKyvD/PnzMXjwYNx44404cOAAtm/fjptuugkAUFRUhJKSEsv5U6ZMwcaNG/Hee+9h9OjR+Oyzz7BlyxaMGDFCqpdgk6Orpfy8VVC0/hKvY/NM2appdP+WC7aIeTeZ+ewzRUT2JWnOzQcffNDp8zt37rzm2Jw5czBnzhwHjch+xJwbrYNmbpRKBQLUXtDpW1CvNwJah9yGJJZ91v1bLtiS1rrfTe6lWlTU6REW4PzcOCKSJ5fLuZELR1dLAe12KWbFlGzJoeWCLZFaHwyJ0kIQgKzWajAiIntgcOMgOgcvSwFtgROXpeRLzLeRSwn41SxLU3lcmiIi+2Fw4yCOLgUHOHMjd+cr6lFcaW65cN0A9265YIulz1QeWzEQkf0wuHEQcVlK64SZG+51I0/ikpQcWi7YMikpFGovJUpqmnD2Sr3UwyEimWBw4yBtMzfeDrsHgxt522PpAi6/fBuRj7cKExNDAHBpiojsh8GNgzi6FBxol3PDZSnZkWPLBVvaL00REdkDgxsH0TW17lDsjJwbztzIjthyIVhGLRdsSW8tCd93rgLNLdyQkoj6jsGNAwiC4JScG3EPnXoGN7IjzmKkyajlgi3DogMR5q9GfbMRR4rYioGI+o7BjQM0GowwtRZ+sFqKekOOLRdsUSoVlg39MvO5NEVEfcfgxgHEYEOhAPzUjut2LCYr6zhzIys1jQbkyLTlgi1inynm3RCRPTC4cQBdu92JFQrHLSlw5kae5NxywRYxafrYhWrUNHBTSiLqGwY3DiDmwDiqr5RIy1JwWZJzywVbooN8kRwZAJMA7D3L2Rsi6hsGNw5g2ePGgcnEACwbuzG4kZdMS3Aj/3yb9sTXu5tLU0TURwxuHEDnhKaZ7a/PfW7k43xFPYoqG2TdcsEWS5+pfG7mR0R9w+DGAdpmbhy3OzHQVmZex8aZsuEJLRdsmZwUBm+VAsWVjThfwVYMRNR7DG4coM5JOTfizE2TwYQWIzc/kwNPaLlgi7/GC+Piza0YuDRFRH3B4MYB6py0LNX+N/t6vdGh9yLHa2nXckHctdfTWJam2GeKiPqAwY0DiDkwjl5WUHspofEy/xHquDTl9o5eaGu5MKK/vFsu2CJWiO3Nr+BsJBH1GoMbBxBzYBxdLQW0z7thUrG7233Gc1ou2DKifxCCfL2h07fg6IUaqYdDRG6KwY0DiAnFjs65AdqWvriRn/vzpJYLtqiUCqQlm6vEMpl3Q0S9xODGASw5N06YuRGXvtiCwb15YssFW8SlqT3MuyGiXmJw4wBizo2jE4rb34MzN+5NbLkwwINaLtgiJlMfKa6Grom5ZETUcwxuHMCZMzfMuZEHsWHkVA+ftQGAuFA/JIX7w2gSLNVjREQ9weDGAZy1zw3AmRu52OOhLRdsEWdvMvOZd0NEPcfgxgGc1Vuq/T04c+O+PLnlgi1t+90wuCGinmNw4wDO6i1lvoe5xQODG/flyS0XbLluYBhUSgXOldfjQlWD1MMhIjfD4MbO9C1GNLeYNx/TahzbWwpol3PDZSm3JbZc4JJUm0Afb4yJCwbA2Rsi6jkGN3bWvg2Cv0bl8PtZcm44c+OW2rdcyGAysRUx2NvD4IaIeojBjZ2JMyi+3ip4qRz/9nKfG/fGlgu2icFN1tlyGE2CxKMhInfC4MbOdE5svQC0r5bifiDuiC0XbBsdGwytxgvVDQbkXmIrBiLqPgY3dubM1gsA97lxd+IuvBke2gW8M14qJVIHmqvHuDRFRD3B4MbOnLmBH8B9btxZTaPB0hwyncnEHWrLu2ErBiLqPgY3dlbnxDJwgPvcuLPssxUwmgQMiPBHbIif1MNxSWKS9aHzVajnZ5yIuonBjZ05O7jRtquWEgQmXbqTti7grJKyJSHMD7EhvjAYBfxUUCn1cIjITTC4sTNn7k7c/j4mAWg0GLs4m1wJWy50TaFQtOsSzrwbIuoeBjd25sy+UoC55FwssmHejfsQWy54KRWYzJYLnWLeDRH1FIMbO9M5eeZGoVBwrxs3JM5CjEsIcdoSpruaMjAMCgWQV1aH0pomqYdDRG6AwY2dteXcOL71gkjLiim305ZvwyWprgT7qTEqNhgAZ2+IqHsY3NiZJefGCa0XRKyYci8tRhP25rPlQk+I+wBl5jPvhoi6xuDGzpy9zw3QVpml48yNW2DLhZ6ztGLIL4eJrRiIqAsMbuxMJ8GyVICP+V6cuXEPlpYLA9lyobvGxofAT61CeV0zfi6tlXo4ROTiGNzYmdjjyZlJomLODTc5cw/i0gpLwLtP7aXEda1VZZksCSeiLjC4sTNLKbgEy1KcuXF9NY0G5BRXA2DLhZ5qKwlncENEnWNwY2dtCcVODG58mHPjLthyoffE4Oanwko0ccNKIuoEgxs7MpoE1Deb/9GVIqG4Tm9w2j2pd9hyofcGRgQgOsgHzS0mHChkKwYiso3BjR3VN7fNnDh15ob73LgNcUklPZlLUj2lUCgs7xuXpoioMwxu7EgMLrxVCmi8nPfWcp8b99C+5cJ1A9lyoTfSmXdDRN3A4MaO2ncEVyicV+LLfW7cA1su9J04c/NzSS2u6PQSj4aIXBWDGztydl8pEWdu3ANbLvRdWIAGw2MCAZg39CMi6giDGzuSoq8UwH1u3AFbLtiP+P5xaYqIbGFwY0dizo3WyUsOnLlxfWLLhSBftlzoq7b9bq5AENiKgYiuxeDGjsRSbKcvSzHnxuW1r5Jiy4W+GZ8QAo2XEmU6PfLK6qQeDhG5IAY3dlSnb93jxskzN9rWZTB9iwnNLSan3pu6Rwxu2HKh73y8VZjc2oph95krEo+GiFwRgxs7qpMoodhfo7L8P/NuXA9bLthfRmvVVCaTiomoAwxu7EhclnJ2zo2XSgkfb2XrGBjcuBq2XLC/jEHm4Gb/uUroW9iKgYisMbixo/b73DibWKHFvBvXI5aAZ3BXYrsZ3E+LCK0GjQYjDp2vkno4RORiehXc1NTUoLLy2t4ulZWVqK2t7fOg3JVU+9wAbV3IOXPjesSlE5aA20/7VgyZLAknoqv0Krh54IEHsGnTpmuOf/LJJ3jggQf6PCh3Je3MDZtnuqLzFfU4X8GWC46QwVYMRGRDr4Kb/fv34/rrr7/m+PTp07F///4+D8pdWfa5kWDmpi24Yf6BK2HLBccRZ25OXKpBVX2zxKMhIlfSq+BGr9ejpeXa5Q+DwYDGxsY+D8pdSbVDMdBuIz/m3LgUtlxwnMhAHwyJ0kIQgKyznL0hoja9Cm4mTZqE995775rj77zzDsaPH9/nQbkrMeemfWm2s2i5LOVyWowm7D1rbrmQznwbhxBnb/acYXBDRG16NU++atUqzJgxA0ePHsWNN94IAPjhhx9w4MABfPfdd3YdoDsRZ26kWJby13DmxtUcvVADXZO55cJItlxwiPSUcLyfWYDM/HIIggCFgrs/E1EvZ27S0tKQnZ2NuLg4fPLJJ/jqq6+QnJyMY8eOISMjw95jdAuCILjEspSO1VIuQ1ySYssFx5mcFAa1SomL1Y04V14v9XCIyEX0eophzJgx+Pjjj+05FrfWZDDBaDI38ZOiFDyAMzcuhy0XHM9XrcKExBDsPVuBzLxyDIwIkHpIROQCevVTuKioqNPn4+PjezUYd6ZrzXVRKAA/bwlybrjPjUupbWLLBWfJSInA3rMV2JNXjgVTEqUeDhG5gF4FN4mJiZ2ubRuNnleObOkrpfaCUoIliLZScAY3rsDSciGcLRccLSMlHH/eBuw7VwGD0QRvFTdeJ/J0vQpujhw5YvW1wWDAkSNH8Je//AUvvviiXQbmbiz5NhIsSQEMblyNpeUCZ20cblh0IEL91aisb0ZOcTUmJoZKPSQiklivfhKPHj36mmMTJkxATEwMXn31Vdxzzz19Hpi7MZoE9A/2RWSgRpL7c58b19KWb8MScEdTKhVISw7HV0cvYc+ZKwxuiMi+jTMHDx6MAwcO2POSbmNsfAiyfn8DNv86TZL7a1srtDhzIz22XHA+sSnpnnzud0NEvZy5ubo5piAIKCkpwYoVK5CSkmKXgVHPcObGdbDlgvOJSdtHi6tR02hAkK/zt2MgItfRq5mb4OBghISEWB6hoaEYNmwYsrOzsXbt2m5fZ/Xq1Zg4cSK0Wi0iIyMxe/ZsnD59utPv2bBhAxQKhdXDx8enNy9DVsRdkeuaW2BqLUknaYhdqsXZBHK8mGBfDIzwh0kAstmKgcjj9erXyh9//NHqa6VSiYiICCQnJ8PLq/uX3LVrF5YsWYKJEyeipaUFf/jDH3DzzTfj5MmT8Pf3t/l9gYGBVkEQdyVtW5YSBKDBYOSMgURajCZLn6OMQcy3caaMlAicvVKPPXnluGVEtNTDISIJ9eon4LRp0wAAJ0+eRFFREZqbm1FVVYUzZ84AAO68885uXWfbtm1WX2/YsAGRkZE4dOgQpk6davP7FAoFoqKiejN02fLxVkKlVMBoElDX1MLgRiJsuSCdjJRwbNhbaFkWJCLP1aufgOfOncM999yDY8eOQaFQQBDMyyDiDEpv97mpqakBAISGdl7tUFdXh4SEBJhMJowbNw4vvfQShg8f3qt7yoVCoUCAxgs1jYbW5plcqpMCWy5IZ/KAMHgpFSiqbMD5inokhNme/SUieetVzs0TTzyBxMRElJWVwc/PDydOnMDu3bsxYcIE7Ny5s1cDMZlMWLZsGdLS0jBixAib5w0ePBjr1q3Dl19+iY8++ggmkwlTpkzBhQsXOjxfr9ejtrbW6iFX4myNjknFkmHLBekEaLwwLiEEADh7Q+ThehXcZGdn44UXXkB4eDiUSiVUKhXS09OxevVq/OY3v+nVQJYsWYITJ05g06ZNnZ6XmpqK+fPnY8yYMZg2bRq++OILRERE4N133+3w/NWrVyMoKMjyiIuL69X43IHYgqFe73k7RLsCtlyQnpjEncnghsij9Sq4MRqN0Gq1AIDw8HBcunQJAJCQkNBltVNHli5diq+//ho//vgjYmNje/S93t7eGDt2LPLz8zt8fvny5aipqbE8iouLezw+d9G2S7FB4pF4JrZckJ6YxL33bDlajCaJR0NEUulVzs2IESNw9OhRJCUlYfLkyXjllVegVqvx3nvvYcCAAd2+jiAIePzxx7F582bs3LkTSUlJPR6L0WjE8ePHcdttt3X4vEajgUYjza7BzibudcNlKWmw5YL0RvYPQpCvN2oaDTh2sQbj4kOkHhIRSaBXMzd//OMfYTKZfyt64YUXUFBQgIyMDHz77bf461//2u3rLFmyBB999BE2btwIrVaL0tJSlJaWorGx0XLO/PnzsXz5csvXL7zwAr777jucO3cOhw8fxoMPPojz58/jkUce6c1LkRV/9peSFFsuSE+lVGBK667QXJoi8ly9mrmZOXOm5f+Tk5Nx6tQpVFZWIiQkpEd7zogb/k2fPt3q+Pr167Fw4UIAQFFREZTKthisqqoKjz76KEpLSxESEoLx48dj7969GDZsWG9eiqxoNdylWCpFFQ1sueAiMlIisPVEKfbkXcFvbuSO6USeyG6boXRVvt0RsYS8M1dXX73++ut4/fXXe3wvT8DO4NLZk29ekhoXz5YLUhOXBY8UVaNOzz2fiDyRXRtnkrQsOTcMbpxuzxmWgLuKuFA/JIb5ocUkYN/ZCqmHQ0QSYHAjIwFclpIEWy64HrEUX0zyJiLPwuBGRtr2uWFw40xsueB60pPNQeaefCYVE3kiBjcyEtDaPJPLUs4lzg6kJYex5YKLSB1o/rM4d6UeF6sbu/4GIpIVBjcyIubccFnKuTJZAu5ygny9MTrWPIuWyaUpIo/D4EZGAjQqAKyWcqbaJgOOiC0XkplM7ErEYJN9pog8D4MbGRGXpRjcOE/7lgtxoWy54ErEyrWs/HKYTF1vO0FE8sHgRka4LOV8bLngukbHBSNA44WqBgNyL9VKPRwiciIGNzIiloI3G03Qt7AzuDOI+TbpzLdxOd4qJVJbd4vezbwbIo/C4EZG2u/EytkbxyuqaECh2HJhQM936CbHE2fU2GeKyLMwuJERlVIBPzWTip2lfcsFrY+3xKOhjohJxYfOV6GhmX8niDwFgxuZYX8p52HLBdeXGOaH/sG+aDaasL+gUurhEJGTMLiRGSYVOwdbLrgHhULBpSkiD8TgRma0nLlximMX2XLBXbTtd8OkYiJPweBGZvwZ3DiFuCTFlguub8rAMCgUwJnLdbhc2yT1cIjICRjcyIyYc6PjspRDte1vwyUpVxfir8ao/mIrBi5NEXkCBjcyY8m54cyNw7DlgvtJb8274dIUkWdgcCMzlpwbztw4DFsuuJ/0ZPMMW2Z+BVsxEHkABjcyw5kbx2vblZizNu5iXEIw/NQqlNfpcapUJ/VwiMjBGNzIDJtnOh7zbdyPxkuFyUnmXaQz87k0RSR3DG5khvvcOBZbLrivtpJwJhUTyR2DG5nhPjeOxZYL7kvczO+ngko0GdhYlkjOGNzIjLjPjY7BjUOw5YL7So4MQL9ADfQtJhwsrJJ6OETkQAxuZMbSW6rJIPFI5KfFaMLes0wmdlfmVgzcrZjIEzC4kRktq6Uc5tjFGtQ2tSDQxwujYoOlHg71QoZlvxvm3RDJGYMbmQngPjcOIy5JpaeEs+WCm0pr3XTxZEktyuv0Eo+GiByFwY3MiNVS9c1GGLlZmV2xBNz9hQdoMCw6EACQlc/ZGyK5YnAjM+LMDQDUN3P2xl7YckE+uDRFJH8MbmRG46WEt8q8ZFLPvBu72dfaciGJLRfcXvukYkHg7CaRHDG4kRmFQsG8GwcQf8tnCbj7m5AYAo2XEpdr9cgvq5N6OETkAAxuZIh73dgf823kw8dbhUmtrRi4NEUkTwxuZIgzN/ZVXMmWC3LTlnfD/W6I5IjBjQxxrxv7En+7Z8sF+UhPNs/A7TtXCX0LWzEQyQ2DGxnizI19ib/dc1di+RgSpUV4gAaNBiMOn6+WejhEZGcMbmQooHV2gTk3fddiNFn2Q2EysXwolQqkJ4cBADLzuTRFJDcMbmSIMzf2w5YL8iUmh2cyqZhIdhjcyJDWsksxg5u+YssF+RKXGY9drEFVfbPEoyEie2JwI0PizI2OMzd9Ji5ZsARcfvoF+mBQvwAIArD3bIXUwyEiO2JwI0PiPjesluobXZMBh4uqAbDlgly1362YiOSDwY0MaS05NwaJR+LestlyQfbS2/WZYisGIvlgcCNDAdznxi7YckH+JieFQq1S4mJ1IworGqQeDhHZCYMbGWLOjX2w5YL8+am9MD4hBACXpojkhMGNDHHmpu/ElgsqtlyQvYxBbUtTRCQPDG5kSMuE4j5ra7kQzJYLMpfR2ooh+2wFDEaTxKMhIntgcCND4sxNvb6FSZK9xCUpzzE8JhAhft6o07fgaHG11MMhIjtgcCNDYs6NwShA38LfRHuKLRc8i1KpQFoyl6aI5ITBjQz5q70s/8+lqZ5jywXPk2EpCWdSMZEcMLiRIaVSAX+1CgD7S/WG2GsoLZktFzxFeuvy49ELNahp5P5QRO6OwY1MsWKq95hv43n6B/tiQIQ/jCYB2WzFQOT2GNzIFPe66Z32LReYb+NZMlrzbsR+YkTkvhjcyFRAa/kyZ256hi0XPJc4U5fJpGIit8fgRqba9rph/kBPsOWC57puYBi8lAoUVjSguJKtGIjcGYMbmQqwNM/kzE1PZLaWgLMLuOcJ0HhhXLzYioGzN0TujMGNTLUlFBslHon7KK5sQEF5PVRKBVIHhkk9HJJAOkvCiWSBwY1MBXBZqsfYcoHE4GZva+4VEbknBjcyxWWpnmMJOI3qH4RAHy/UNBpw/GKN1MMhol5icCNT4rKUjtVS3WI0CWy5QPBSKTFlYOvS1BkuTRG5KwY3MsWZm545dqGaLRcIAJAxqDW4yWdSMZG7YnAjU1ruUNwje9hygVplJJuXJQ+fr+LfHyI3xeBGptoSivmPc3cw34ZE8WF+iA/1Q4tJwP5zbMVA5I4Y3MgUl6W6jy0X6GptXcK5NEXkjhjcyBQbZ3bfvnOVbLlAVjK43w2RW2NwI1NaDXtLdZf4A4y7EpModWA4lArg7JV6XKpulHo4RNRDDG5kyl+jAgA0NBu5GVkX2E+Krhbk643RccEA2EiTyB0xuJEpcVkK4OxNZ9hygWzJSGZJOJG7YnAjUxovFdQq8x8vgxvb2HKBbMkYZK6cy8ovh4mzn0RuhcGNjFmSilkxZVNmPkvAqWNj4oIRoPFCZX0zTpbUSj0cIuoBBjcyxuaZnTOaBEs+RTrzbegq3iolrhtgXqpkSTiRe2FwI2NicKPjzE2HrFou9A+SejjkglgSTuSeGNzIGPe66Vz7lgteKv5VoGuJM3oHC6vQ2GyUeDRE1F2S/ou+evVqTJw4EVqtFpGRkZg9ezZOnz7d5fd9+umnGDJkCHx8fDBy5Eh8++23Thit+9G2ztzUM7jpEFsuUFcGhPujf7Avmo0m/FRYKfVwiKibJA1udu3ahSVLlmDfvn3YsWMHDAYDbr75ZtTX19v8nr1792Lu3Ll4+OGHceTIEcyePRuzZ8/GiRMnnDhy9yDO3HBZ6lq6JgOOsOUCdUGhUFg2d9xzhktTRN3RYjRB1yRtrqekwc22bduwcOFCDB8+HKNHj8aGDRtQVFSEQ4cO2fyeN954A7fccgt++9vfYujQofjf//1fjBs3Dm+++aYTR+4e/Nk806Z95yrRYhKQGObHlgvUqYxB5uAmk/vdEHWqptGAv+8+h2mv7sQr27pehXEkr65PcZ6amhoAQGhoqM1zsrOz8dRTT1kdmzlzJrZs2eLIobklLZtn2sQlKequtIHhUCiAU6U6lNU2ITLQR+ohEbmUgvJ6bMgqwKeHLqChNTftv6fK8LzRJFk+o8sENyaTCcuWLUNaWhpGjBhh87zS0lL069fP6li/fv1QWlra4fl6vR56vd7ydW2t5+xXEcCZG5vYcoG6K8RfjRExQTh+sQaZ+eW4Z1ys1EMikpwgCNh7tgLrMgvw39NlEFr3uRzcT4vF6Ym4a0x/SQs1XCa4WbJkCU6cOIHMzEy7Xnf16tVYuXKlXa/pLiw5NwxurLDlAvVURkq4ObjJY3BDnq3JYMSXORexLrMQpy/rLMdvHBKJxelJmDIwDAqFQsIRmrlEcLN06VJ8/fXX2L17N2JjO/+HIyoqCpcvX7Y6dvnyZURFRXV4/vLly62WsWpraxEXF9f3QbuBAC5LdUjMnWDLBequ9JRwvL3zLPbkl0MQBJf4x5vImcpqm/DRvvP4aH8RKuubAQC+3irMmRCLhVMSMSAiQOIRWpM0uBEEAY8//jg2b96MnTt3IikpqcvvSU1NxQ8//IBly5ZZju3YsQOpqakdnq/RaKDRaOw1ZLei5T43HRLzbdKTmW9D3TM+IQS+3ipc0elx+rIOQ6ICpR4SkVMcv1CD9VkF+OrYJRiM5rWn/sG+WDAlAfdPiEeQn2v+gihpcLNkyRJs3LgRX375JbRarSVvJigoCL6+vgCA+fPno3///li9ejUA4IknnsC0adPw2muv4fbbb8emTZtw8OBBvPfee5K9DlcVoDF/6LjPTZv2LRfEKhiirmi8VJg8IBQ7T1/BnjPlDG5I1owmATtOlmJdZqHV/k4TEkKwOD0JNw/r5/Ibn0oa3KxduxYAMH36dKvj69evx8KFCwEARUVFUCrb3sQpU6Zg48aN+OMf/4g//OEPSElJwZYtWzpNQvZU3OfmWmy5QL2VnhxuDm7yy/Ho1AFSD4fI7mqbDPjkQDE27C3EhapGAICXUoE7RkVjUVoSRscFSzvAHpB8WaorO3fuvObYnDlzMGfOHAeMSF4CNCoAXJZqjy0XqLemDooAvvkZPxVUoMlghI+3SuohEdlFYXk9NuwtxKcHi1HfWsod4ueN/5kcj4euS0RUkPttf+ASCcXkGOKyVJ2+hUmQrSxLUtzfhnooJTIA/QI1uFyrx6HzVUhL5rImuS9BEJB9zlzK/cOptlLulMgALE5Pwuwx/eGrdt8AnsGNjInLUkaTgCaDya0/qPagazLgcFEVAO5vQz1nbsUQgc8PX8CevHIGN+SWmgxG/OfoJazLLMCp0rZS7usHR2BxehLSk8Nl8YswgxsZ8/NWQaEABAHQ6Q0eH9yw5QL1VUZKeGtwcwW/v3WI1MMh6rYyXRM+2leEj/edR0W7Uu5fjI/FwrREDHSxUu6+YnAjY0qlAgFqL+j0LahrakGkVuoRSYstF6ivxNma3Eu1qKjTIyzAM7eZIPdx4mIN1mUV4KujbaXcMUE+WDAlEQ9MdN1S7r5icCNzAT6twQ2TitlygfosQqvB0OhA/FxSi6yzFbhzdIzUQyK6hrmU+zLWZRXgp4K2Uu5x8cFYnJ6EW4ZHyb6ggsGNzHGXYrP2LReuY8sF6oOMlHD8XFKLPWeuMLghl6JrMuCTgxewYW8BiivbSrlvGxmNRWmJGBsfIvEInYfBjcwFcJdiAG0tF8bGBSOQLReoDzJSwvHe7nPIZCsGchHnK8RS7guWf+uD/bzxP5Pi8VBqAqKDfCUeofMxuJE5dgY3Y74N2cvExFCovZQoqWnC2St1SPb0ZDaShCAI2HeuEuuyCvD9z5ctpdzJkQFYnJaEu8e6dyl3XzG4kTkGN+b156z8CgBsuUB95+OtwqTEUGTml2NPXjmDG3IqfYsR/8m5hHVZhfi5pNZyfPrgCCxOS0JGijxKufuKwY3MicGNJ7dgOH6xBjWNBrZcILvJSAlHZn45MvPKsSit64a/RH11RafHx/vP46N951FeZy7l9vFWmku5pyQhOVJepdx9xeBG5phzA+w5Y16SmjKQLRfIPtJTwoGtQPa5CjS3mKD24ueKHCP3Ug3WZxXiPzmX0Gw0AQCig3wwPzURcyfFIdhPLfEIXRODG5nTslqqrQScS1JkJ0OjAhEeoEZ5XTOOFFVh8gBW4JH9GE0CfvjZXMq971xbKffY+GAsTkvCLSOi4M1f1DrF4EbmPH3mpn3LhalMJiY7USoVSEsOx5c5l7Anr5zBDdmFrsmATw9ewIa9hSiqbAAAqNqVco/zoFLuvmJwI3Ni80xPzblhywVylIyUCHNwk1+OZ2YOlno45MaKKhqwYW8hPjlYbPlFNMjXG3MnxWN+agJigj2vlLuvGNzInDhzU++hMzeZLAEnB0lvbcVw/EI1qhuamftAPSIIAn4qqMQHmQXY0a6Ue2CEPxalJeGecf3hp+aP6N7iOydzWg8vBRfzbdLZcoHsLCrIBymRAcgrq8PesxW4bWS01EMiN6BvMeLroyVYl1WA3EttpdxTB0VgcVoipqZEQKlkKXdfMbiROX8PDm6KKxtwrrXlQipbLpADZKREIK+sDnvyyhncUKfK6/T4eF8R/rnvPMrr9ADMpdz3jIvFoimJSOnH/ZLsicGNzHnyPjdsuUCOlpESjnVZBdiTd4WtGKhDJy/VYn1WAb5sV8odFeiD+VMSMHdiPEL8uZzpCAxuZE5rqZYySDwS52PLBXK0yQNC4a1S4EJVI85XNCAx3F/qIZELMJoE/PdUGdZlFiD7XIXl+Oi4YDycnoRbWcrtcAxuZE6cuWkymGAwmjzmLxRbLpAz+Km9MD4hBPvOVWJPfjmDGw9Xp2/BZweLsX5vIc5XtJVy3zoiCovTk1jK7UQMbmROzLkBzBVTnlLRIbZc0LLlAjlYRkqEObg5cwUPXZcg9XBIAsWVDfjH3kL8+0AxdK35jYE+Xpg7OR7zUxPRn6XcTsfgRubUXkpovJTQt5iga/Kc4EZsuZDGlgvkYBkp4Xh1+2lkn61Ai9HEz5uHEAQBBwqrsC6zAN+dLIWptZR7QGsp970s5ZYU33kPoPXxgr6u2aMqpthygZxleEwQgv28Ud1gwNEL1RifECr1kMiBmltM+PrYJazLKsCJi22l3Bkp4VicnoRpLOV2CQxuPECAxgvldc0es5Ffnb6FLRfIaVStrRi+OVaCPXnlDG5kqqJOj4/3m0u5r+jMpdwar9ZS7rREDGIpt0thcOMBxLwbnYcEN/vOVrDlAjlVRmtwk5lXjmUzBkk9HLKjU6W1WJ9ZiM05F9HcYi7l7heoae3KHY9QlnK7JAY3HiDAwzqDiyXg3JWYnEX8rB0prkZtk4H7Krk5k0nAj6fLsC6rwFJ1CQCjYoNaS7mjofZibpUrY3DjAbQe1hnckm/DJSlyktgQPwwI98e58nrsO1uBm4dHST0k6oV6fQs+O3QB67MKUNhayq1UALeOiMbidHNXbm7U6B4Y3HgAT5q5YcsFkkp6SjjOlddjT145gxs3U1zZgA+zC7HpQLFlN3etjxf+Z1I8HkpNQGwIl7fdDYMbDyB2BveEnBu2XCCpZKRE4MPs85bPILk2QRBw8Ly5lHt7brtS7nB/LEpLxD3jYq32CSP3wj85DxCgMf+Q94SZm0wuSZFErhsQCpVSgYLyehRXNjCZ3UU1t5jw7XFzV+5jF2osx9OTw7E4PRHTB0WylFsGGNx4AE/pL2U0CZbfmplMTM6m9fHG2LhgHDxfhcz8csydFC/1kKidyvpmbNx/Hh9mn0dZaym32kuJe8b2x6K0JAyOYim3nDC48QBizk293ijxSByrfcuF0bFsuUDOl5ESYQ5u8hjcuIrTpTqszyrA5iMXoW8t5Y7UajA/NQFzJ8UjLEAj8QjJERjceABP2eeGLRdIaukp4Xj9+zPIzC+H0SRAxeUNSZhMAnaduYJ1WQWW6kkAGNnfXMp920iWcssdgxsP0FYtJe9lKbZcIKmNjg2C1scLNY0GnLhYg9FxwVIPyaPU61vwxeELWJ9ViHPl9QDMpdy3jIjC4rQkjE9gKbenYHDjATxhnxu2XCBX4KVSYsrAMGzPvYzM/HIGN05ysboRH+4txL9+KkJtu1LuBybGYX5qIpO7PRCDGw/gCfvciC0XEthygSSWnhKB7bmXsfvMFSy5Plnq4ciWIAg4XFSFdZmF2JZbCmNrLXdimJ+5K/f4WMu/feR5+CfvATxhnxux5UIGq6RIYlNbP4OHi6pQr2/hXil21txiwtYTJViXWYCj7Uq505LDsDgtCdcPZik3MbjxCFpN27KUIAiyXHNmywVyFQlh/ogL9UVxZSP2F1TghiH9pB6SLFTVN2PjT0X4MLsQl2vbSrnvHtMfi9ITMSQqUOIRkithcOMBxJkbQQAamo2y+03yQhVbLpBryUiJwMb9RdiTV87gpo/yLuuwLqsQXxy+YCnljtBq8NB1CZg3maXc1DF5/ZSjDvl6q6BUACbBPHsjt+BG3JWYLRfIVWQkh2Pj/iLLZ5N6xmQSsCvvCtZlWpdyD48JxMPpSbh9VDQ0XioJR0iuTl4/5ahDCoUCARov1Da1oE7fArn9Hin+48ddiclVTBkYDqUCyCurQ0lNI6KDfKUekltoaG7B54cvYn1WAc5daSvlvnlYFBanJ2FiIku5qXsY3HgIS3Ajs4qp9i0XmG9DriLIzxujYoORU1yNzLxyzJkQJ/WQXNql6kb8I7sQ/9rfrpRb44X7J8ZhwRSWclPPMbjxEAE+XkCN/Pa6YcsFclUZKeHIKa7GHgY3Nh06X4V1WQXYdqKtlDshzA+LpiTiFxPiWMpNvcZPjocQ/5HQyWzmJjOPLRfINWWkROBv/81HVn45TCaB5cmtDEYTtp4oxbrMAuQUV1uOTxnYWso9JJJtK6jPGNx4iIDWRFu5zdzsZssFclFj44Phr1ahor4ZP5fWYniMZ88sVtU3418HivDh3vMorW0CYC7lnj0mBovSkjA0mqXcZD8MbjyEVob9per0LTh83txyISOZ+TbkWrxVSlw3IAw/nCrDnrxyjw1u8svaSrmbDOZS7vCA1lLu6+IRzlJucgAGNx4iQCO//lLtWy7EhzHhkFxPRko4fjhVhsy8cvxy2kCph+M0giB25S7E7jNXLMeHRZtLue8YzVJuciwGNx5Cji0Y2HKBXF16awXfT4WVaDIY4eMt7x/ojc1GfHHE3JU7v6wOAKBQADcP64fFaUmYlBTKUm5yCgY3HkKcuamXU3DDEnBycQMj/BET5INLNU34qaASUwfJ87NaUtOID7PPY+P+ItQ0mpe+AzReuG9CHBZOSeTMKjkdgxsPIbfO4BeqGnDuClsukGtTKBRITwnHJwcvIDO/XHbBzZGiKqzLKsS3x0sspdzxoX5YOCURcybEQssdw0kiDG48hLgsJZecG3Fb+zFsuUAuLj0lAp8cvIDdZ67gD7cNlXo4fWYwmrDtRCnWZRXgSFG15fh1A0KxOC0JNw7tx1JukhyDGw8ht31u2rqAM9+GXFt6cjgUCuBUqQ5luiZEan2kHlKvVDc0418/FePD7EKU1LSWcquUuHNMDBalJXpsNRi5JgY3HkJOMzdsuUDuJNRfjeExgThxsRZZ+eW4e2ys1EPqkfyyOqzPKsDnVqXcajx4XQLmTU5AhJal3OR6GNx4CK2MSsFPsOUCuZmMlAicuFiLPXnuEdwIgoA9eeVYl1WAnafbSrmHtpZyz2IpN7k4BjcewjJzI4NlKbEEfMrAMLZcILeQkRyOtTvPIjOvHIIguGw5dGOzEZuPmLty57Ur5Z4x1FzKfd0AlnKTe2Bw4yEsOTcymLmxtFzgkhS5ifGJIfDxVqJMp8eZy3UYHKWVekhWSmua8GF2ITb+VITqBnMpt79ahfsmmku5E8L8JR4hUc8wuPEQWo25oqi5xYTmFhPUXu4549G+5cJUBjfkJjReKkxOCsOuM1ewJ++KywQ3OcXVWJ9VgG+OlaCltZQ7LtQXC6ckYc6EWFYiktticOMh/DVt6+P1+haovdQSjqb32HKB3FVGSnhrcFOORzIGSDaOFqMJ23MvY11WAQ61/qIAAJOTQrE4PQkzWMpNMsDgxkN4qZTw8VaiyWBCnb4FIf7uGdy0VUmxBJzci3kZ9WfsL6iAvsXo9ITcmgYDNh0owj/2FuJSaym3t0qBWaNjsDgtCSP6Mzmf5IPBjQcJ0HijyaB3671udrcmE6ezCzi5mUH9AhCp1aBMp8eh81WYMtA5AfrZK3XYkFWIzw5dQKPBCAAI81dj3nUJePC6eLfdd4eoMwxuPIjWxwvldXq3LQdnywVyZ2Irhi8OX8SevHKHBjeCYN4Lal1mAX5sV8o9JEqLxelJuHN0jOybeJJnY3DjQSz9pfQGiUfSO+1bLgT5MtGR3E9Ga3CTmVeO391i/+s3GYzYcuQi1mUV4MzltlLuG4f0w+L0RKQOCGMpN3kEBjcexN1bMOxhvg25ubRk82f3xKUaVNY3I9ROuW+Xa5vwz+zz+Hj/eVS1K+We09qVOzGcpdzkWRjceBB3bsFgNAnIYssFcnORWh8MidLiVKkOWfnlmDU6pk/XO3ahGusyC/B1u1Lu/sG+WJSWiPsmxrGUmzwWgxsPYmnB4IYzNycu1qC6gS0XyP1lpITjVKkOmXm9C25ajCZ8d/Iy1mUW4GC7Uu5JiaFYnJ6IGUP7cedu8ngMbjyIf2twU++GMzdsuUBykZESgb/vKcCevCs9asVQ02jAvw8U4R97z+NidSOA1lLuUTFYlJaEkQz6iSwY3HgQcVnKHVswsOUCycWkpFCovZS4VNOEc+X1GBgR0On5BeX12JBVgE8PXUBDs7mUO9RfjQcnx+PB6xIQGchSbqKrMbjxIAFuuixVp2/BkSK2XCB58PFWYWJiCLLyK7DnzJUOgxtBELD3bAXWZRbgv6fLIJjTacyl3GlJuHMMS7mJOsPgxoNo3TSheP+5ChiMbLlA8pGREoGs/Apk5pdjYVqS5XiTwYgvcy5iXWYhTl/WARC7ckdicVoSUgeylJuoOxjceJC2fW7sH9y0GE1oMBjR1GxEQ+uj0WBEY+t/G5pb0GSwPm51TrOx7fsNLVbHxByh9GSWgJM8iJ/l7LMVMBhNqKpvxj/3ncfH+4tQWd8MAPBTqzBnfCwWpiUhiaXcRD3C4MaDiMHNFZ0eJy7WWAUZYuDRURDSaLj6HPH/WyzPG4yCQ8furVJg9tj+Dr0HkbMMiw5EmL8aFfXNWLzhAPa1zk4C5lLuhVPMpdzcrJKodyQNbnbv3o1XX30Vhw4dQklJCTZv3ozZs2fbPH/nzp24/vrrrzleUlKCqKgoB45UHsSE4lOlOtzxt0yH3EOpAPzUXvBVq+DrrYKfWgWf1v+2/39fbxV81V6Wc6zOV6vg520+Zn7OC8G+3pZqLyJ3p1QqkJYcjv8cvYQ9rcnyExNDsDgtCTcNYyk3UV9J+tOivr4eo0ePxuLFi3HPPfd0+/tOnz6NwMBAy9eRkZGOGJ7sjIoNxpAoLS5WN14VYCjhp/bqJAhRtQYsSvh6e7UFHe0DkNb/V6uUzAkg6oYFUxKRU1yNcfHBWJyehFGxwVIPiUg2JA1ubr31Vtx66609/r7IyEgEBwfbf0AyF6DxwrZlU6UeBhEBGJ8Qgt3/79qZaCLqO7ec+xwzZgyio6Nx0003ISsrq9Nz9Xo9amtrrR5EREQkX24V3ERHR+Odd97B559/js8//xxxcXGYPn06Dh8+bPN7Vq9ejaCgIMsjLi7OiSMmIiIiZ1MIguDYMpduUigUXSYUd2TatGmIj4/HP//5zw6f1+v10Ov1lq9ra2sRFxeHmpoaq7wdIiIicl21tbUICgrq1s9vty8/mTRpEjIzbVf+aDQaaDQaJ46IiIiIpORWy1IdycnJQXR0tNTDICIiIhch6cxNXV0d8vPzLV8XFBQgJycHoaGhiI+Px/Lly3Hx4kV8+OGHAIA1a9YgKSkJw4cPR1NTE95//33897//xXfffSfVSyAiIiIXI2lwc/DgQatN+Z566ikAwIIFC7BhwwaUlJSgqKjI8nxzczOefvppXLx4EX5+fhg1ahS+//77Djf2IyIiIs/kMgnFztKThCQiIiJyDT35+e32OTdERERE7TG4ISIiIllhcENERESywuCGiIiIZIXBDREREckKgxsiIiKSFbdvv9BTYuU7u4MTERG5D/Hndnd2sPG44Ean0wEAu4MTERG5IZ1Oh6CgoE7P8bhN/EwmEy5dugStVguFQtHr64jdxYuLi7kZoIPxvXYevtfOxffbefheO4+j3mtBEKDT6RATEwOlsvOsGo+buVEqlYiNjbXb9QIDA/kXxUn4XjsP32vn4vvtPHyvnccR73VXMzYiJhQTERGRrDC4ISIiIllhcNNLGo0Gzz//PDQajdRDkT2+187D99q5+H47D99r53GF99rjEoqJiIhI3jhzQ0RERLLC4IaIiIhkhcENERERyQqDGyIiIpIVBje99NZbbyExMRE+Pj6YPHkyfvrpJ6mHJDu7d+/GrFmzEBMTA4VCgS1btkg9JNlavXo1Jk6cCK1Wi8jISMyePRunT5+WeliytHbtWowaNcqywVlqaiq2bt0q9bA8wssvvwyFQoFly5ZJPRTZWbFiBRQKhdVjyJAhko2HwU0v/Pvf/8ZTTz2F559/HocPH8bo0aMxc+ZMlJWVST00Wamvr8fo0aPx1ltvST0U2du1axeWLFmCffv2YceOHTAYDLj55ptRX18v9dBkJzY2Fi+//DIOHTqEgwcP4oYbbsBdd92F3NxcqYcmawcOHMC7776LUaNGST0U2Ro+fDhKSkosj8zMTMnGwlLwXpg8eTImTpyIN998E4C5X1VcXBwef/xx/P73v5d4dPKkUCiwefNmzJ49W+qheIQrV64gMjISu3btwtSpU6UejuyFhobi1VdfxcMPPyz1UGSprq4O48aNw9tvv41Vq1ZhzJgxWLNmjdTDkpUVK1Zgy5YtyMnJkXooADhz02PNzc04dOgQZsyYYTmmVCoxY8YMZGdnSzgyIvupqakBYP6hS45jNBqxadMm1NfXIzU1VerhyNaSJUtw++23W/27TfaXl5eHmJgYDBgwAPPmzUNRUZFkY/G4xpl9VV5eDqPRiH79+lkd79evH06dOiXRqIjsx2QyYdmyZUhLS8OIESOkHo4sHT9+HKmpqWhqakJAQAA2b96MYcOGST0sWdq0aRMOHz6MAwcOSD0UWZs8eTI2bNiAwYMHo6SkBCtXrkRGRgZOnDgBrVbr9PEwuCEiK0uWLMGJEyckXS+Xu8GDByMnJwc1NTX47LPPsGDBAuzatYsBjp0VFxfjiSeewI4dO+Dj4yP1cGTt1ltvtfz/qFGjMHnyZCQkJOCTTz6RZLmVwU0PhYeHQ6VS4fLly1bHL1++jKioKIlGRWQfS5cuxddff43du3cjNjZW6uHIllqtRnJyMgBg/PjxOHDgAN544w28++67Eo9MXg4dOoSysjKMGzfOcsxoNGL37t148803odfroVKpJByhfAUHB2PQoEHIz8+X5P7MuekhtVqN8ePH44cffrAcM5lM+OGHH7hmTm5LEAQsXboUmzdvxn//+18kJSVJPSSPYjKZoNfrpR6G7Nx44404fvw4cnJyLI8JEyZg3rx5yMnJYWDjQHV1dTh79iyio6MluT9nbnrhqaeewoIFCzBhwgRMmjQJa9asQX19PRYtWiT10GSlrq7OKuovKChATk4OQkNDER8fL+HI5GfJkiXYuHEjvvzyS2i1WpSWlgIAgoKC4OvrK/Ho5GX58uW49dZbER8fD51Oh40bN2Lnzp3Yvn271EOTHa1We03emL+/P8LCwphPZmfPPPMMZs2ahYSEBFy6dAnPP/88VCoV5s6dK8l4GNz0wv33348rV67gueeeQ2lpKcaMGYNt27Zdk2RMfXPw4EFcf/31lq+feuopAMCCBQuwYcMGiUYlT2vXrgUATJ8+3er4+vXrsXDhQucPSMbKysowf/58lJSUICgoCKNGjcL27dtx0003ST00ol67cOEC5s6di4qKCkRERCA9PR379u1DRESEJOPhPjdEREQkK8y5ISIiIllhcENERESywuCGiIiIZIXBDREREckKgxsiIiKSFQY3REREJCsMboiIiEhWGNwQERGRrDC4ISIiIllhcENERESywuCGiGTBZDLhlVdeQXJyMjQaDeLj4/Hiiy9KPSwikgAbZxKRLCxfvhx///vf8frrryM9PR0lJSU4deqU1MMiIgmwcSYRuT2dToeIiAi8+eabeOSRR6QeDhFJjMtSROT2fv75Z+j1etx4441SD4WIXACDGyJye76+vlIPgYhcCIMbInJ7KSkp8PX1xQ8//CD1UIjIBTChmIjcno+PD373u9/h//2//we1Wo20tDRcuXIFubm5ePjhh6UeHhE5GYMbIpKFP/3pT/Dy8sJzzz2HS5cuITo6Gr/85S+lHhYRSYDVUkRERCQrzLkhIiIiWWFwQ0RERLLC4IaIiIhkhcENERERyQqDGyIiIpIVBjdEREQkKwxuiIiISFYY3BAREZGsMLghIiIiWWFwQ0RERLLC4IaIiIhkhcENERERycr/D8oxy4W4DGptAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs = [0.05, 0.1, 0.3, .5, 1, 2, 3, 5]\n",
    "cv_lr_l1 = [auc_cv(LogisticRegression(solver='saga', penalty='l1', C = c)).mean() \n",
    "            for c in cs]\n",
    "cv_ridge = pd.Series(cv_lr_l1, index = cs)\n",
    "cv_ridge.plot(title = \"logistic regression Validation\")\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VXHH5d3v9--N"
   },
   "outputs": [],
   "source": [
    "# xgb = XGBClassifier()\n",
    "# xgb.fit(X_ohe, y)\n",
    "# importances = xgb.feature_importances_\n",
    "# importances = pd.Series(importances)\n",
    "# importances.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vswHVs-D_K2j"
   },
   "outputs": [],
   "source": [
    "# importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-_MPtSh_-qw",
    "outputId": "468bb5ad-5f5c-481d-8e63-f176aeb66a08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 8, 'reg_alpha': 5, 'reg_lambda': 3}\n",
      "Best score:  0.8102812522133365\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  13.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  12.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  12.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  13.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  14.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   8.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  12.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  13.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  13.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   7.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  13.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  15.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   7.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  12.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  14.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  13.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=  10.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  12.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  13.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   7.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   7.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  12.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  12.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  13.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  15.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=   8.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   8.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=3; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=1; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   9.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=1, reg_lambda=3; total time=   8.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=3, reg_alpha=10, reg_lambda=1; total time=  10.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=1, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=1; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=1, reg_lambda=1; total time=  12.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  12.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=0.5; total time=  12.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.05, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  12.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=0.5; total time=   8.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   8.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   8.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=1, reg_lambda=1; total time=  11.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=5, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  14.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=1, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=0.5; total time=  12.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  11.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, reg_alpha=10, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=1, reg_lambda=1; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=0.5; total time=   9.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=5, reg_lambda=1; total time=   9.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=0.5; total time=   8.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=3, reg_alpha=10, reg_lambda=1; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=0.5; total time=   9.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=1, reg_lambda=3; total time=   8.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=0.5; total time=   9.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=0.5; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=5, reg_alpha=10, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=0.5; total time=  10.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=1, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=1; total time=  10.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=1; total time=  10.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.3, max_depth=8, reg_alpha=10, reg_lambda=3; total time=   8.2s\n"
     ]
    }
   ],
   "source": [
    "params = { 'max_depth': [3, 5, 8],\n",
    "           'colsample_bytree': [0.3, .7, 1],\n",
    "             'reg_alpha': [1, 5, 10],\n",
    "            'reg_lambda': [.5, 1, 3],\n",
    "         'learning_rate': [.05, .1, .3]}\n",
    "xgbc = XGBClassifier(random_state=1)\n",
    "clf = GridSearchCV(estimator=xgbc,\n",
    "                   param_grid=params,\n",
    "                   verbose=2, cv=5, n_jobs=-1, scoring=auc_scorer)\n",
    "clf.fit(X_train, y_train, verbose=False)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Best score: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 100, 'reg_alpha': 3, 'reg_lambda': 2}\n",
      "Best score:  0.809925897029478\n"
     ]
    }
   ],
   "source": [
    "params = { 'max_depth': [8, 12],\n",
    "            'n_estimators': [100, 200],\n",
    "           'colsample_bytree': [0.3, .7],\n",
    "             'reg_alpha': [3, 5, 7],\n",
    "            'reg_lambda': [2, 3, 5],\n",
    "         'learning_rate': [.5, .3]}\n",
    "xgbc = XGBClassifier(random_state=1)\n",
    "clf = GridSearchCV(estimator=xgbc,\n",
    "                   param_grid=params,\n",
    "                   verbose=2, cv=5, n_jobs=-1, scoring=auc_scorer)\n",
    "clf.fit(X_train, y_train, verbose=False)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Best score: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      0.602708\n",
       "0      0.025428\n",
       "3      0.017976\n",
       "257    0.016036\n",
       "63     0.013131\n",
       "         ...   \n",
       "209    0.000000\n",
       "211    0.000000\n",
       "96     0.000000\n",
       "213    0.000000\n",
       "162    0.000000\n",
       "Length: 318, dtype: float32"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(colsample_bytree=0.7, learning_rate=0.3, max_depth=8, reg_alpha=3, reg_lambda=2)\n",
    "xgb.fit(X_train, y_train)\n",
    "pd.Series(xgb.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9010473694587424"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  17.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  20.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  20.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  20.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  20.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  23.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  28.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  22.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  17.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  21.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  24.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  21.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  20.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  29.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  26.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  22.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  20.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  21.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  23.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  13.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  18.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  17.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  13.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  30.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  26.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  23.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  22.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  20.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  21.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  21.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  17.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  26.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  19.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  20.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  17.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  18.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  23.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  31.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  23.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  23.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  20.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  18.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  18.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  22.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  20.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  17.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  20.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  20.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  29.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  26.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  22.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  20.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  21.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  21.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  15.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  14.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  19.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  20.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  23.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  29.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  23.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  22.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  15.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  21.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  21.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  18.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  15.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  13.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  19.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  10.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  13.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  19.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  20.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  30.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  21.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  23.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  12.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  20.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  19.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=  11.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  11.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  18.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  20.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  20.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=2; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  10.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=5; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  17.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  11.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  12.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  12.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  19.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  20.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  29.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  26.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.5, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  23.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=3; total time=   9.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=   9.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=3; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=   9.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=2; total time=  15.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  13.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=2; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=8, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=2; total time=  10.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=3, reg_lambda=5; total time=  10.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=2; total time=  11.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=5, reg_lambda=5; total time=  11.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=3; total time=  11.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=100, reg_alpha=7, reg_lambda=5; total time=  12.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=3; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=3, reg_lambda=5; total time=  18.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=5, reg_lambda=3; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=2; total time=  21.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=3; total time=  20.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.3, max_depth=12, n_estimators=200, reg_alpha=7, reg_lambda=5; total time=  17.7s\n"
     ]
    }
   ],
   "source": [
    "yhat = xgb.predict_proba(X_test)\n",
    "roc_auc_score(y_test, yhat[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age upon Outcome</th>\n",
       "      <th>Age upon Intake</th>\n",
       "      <th>Is_fixed</th>\n",
       "      <th>Time_in_shelter</th>\n",
       "      <th>Normal_condition</th>\n",
       "      <th>Primary_color_Agouti</th>\n",
       "      <th>Primary_color_Apricot</th>\n",
       "      <th>Primary_color_Black</th>\n",
       "      <th>Primary_color_Blue</th>\n",
       "      <th>Primary_color_Brown</th>\n",
       "      <th>...</th>\n",
       "      <th>Primary_breed_Welsh Terrier</th>\n",
       "      <th>Primary_breed_West Highland</th>\n",
       "      <th>Primary_breed_Whippet</th>\n",
       "      <th>Primary_breed_Wire Hair Fox Terrier</th>\n",
       "      <th>Primary_breed_Wirehaired Pointing Griffon</th>\n",
       "      <th>Primary_breed_Wirehaired Vizsla</th>\n",
       "      <th>Primary_breed_Wolf Hybrid</th>\n",
       "      <th>Primary_breed_Yorkshire Terrier</th>\n",
       "      <th>Animal Type_x_Cat</th>\n",
       "      <th>Animal Type_x_Dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>8729.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>8836.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>7614.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>-2438.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age upon Outcome  Age upon Intake  Is_fixed  Time_in_shelter  \\\n",
       "0               730              730         1           8729.0   \n",
       "1               365              365         1           8836.0   \n",
       "3               120              120         1           7614.0   \n",
       "4               120              120         1          -2438.0   \n",
       "5                 6                6         0            276.0   \n",
       "\n",
       "   Normal_condition  Primary_color_Agouti  Primary_color_Apricot  \\\n",
       "0                 1                 False                  False   \n",
       "1                 1                 False                  False   \n",
       "3                 1                 False                  False   \n",
       "4                 1                 False                  False   \n",
       "5                 0                 False                  False   \n",
       "\n",
       "   Primary_color_Black  Primary_color_Blue  Primary_color_Brown  ...  \\\n",
       "0                False               False                 True  ...   \n",
       "1                False               False                False  ...   \n",
       "3                False               False                False  ...   \n",
       "4                False               False                False  ...   \n",
       "5                False               False                False  ...   \n",
       "\n",
       "   Primary_breed_Welsh Terrier  Primary_breed_West Highland  \\\n",
       "0                        False                        False   \n",
       "1                        False                        False   \n",
       "3                        False                        False   \n",
       "4                        False                        False   \n",
       "5                        False                        False   \n",
       "\n",
       "   Primary_breed_Whippet  Primary_breed_Wire Hair Fox Terrier  \\\n",
       "0                  False                                False   \n",
       "1                  False                                False   \n",
       "3                  False                                False   \n",
       "4                  False                                False   \n",
       "5                  False                                False   \n",
       "\n",
       "   Primary_breed_Wirehaired Pointing Griffon  Primary_breed_Wirehaired Vizsla  \\\n",
       "0                                      False                            False   \n",
       "1                                      False                            False   \n",
       "3                                      False                            False   \n",
       "4                                      False                            False   \n",
       "5                                      False                            False   \n",
       "\n",
       "   Primary_breed_Wolf Hybrid  Primary_breed_Yorkshire Terrier  \\\n",
       "0                      False                            False   \n",
       "1                      False                            False   \n",
       "3                      False                            False   \n",
       "4                      False                            False   \n",
       "5                      False                            False   \n",
       "\n",
       "   Animal Type_x_Cat  Animal Type_x_Dog  \n",
       "0               True              False  \n",
       "1              False               True  \n",
       "3              False               True  \n",
       "4              False               True  \n",
       "5               True              False  \n",
       "\n",
       "[5 rows x 318 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 87115, number of negative: 83025\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 785\n",
      "[LightGBM] [Info] Number of data points in the train set: 170140, number of used features: 222\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "Best parameters: {'lambda_l1': 3, 'learning_rate': 0.3, 'num_iterations': 500}\n",
      "Best score:  0.8111496414717292\n"
     ]
    }
   ],
   "source": [
    "#boosting_type='dart', feature_fraction=0.9, learning_rate=1, max_depth=6, num_iterations=300, objective='binary'\n",
    "lgbm = LGBMClassifier(boosting_type='dart', objective='binary', num_threads=10)\n",
    "params = {\n",
    "         'num_iterations': [100, 300, 500],\n",
    "         'learning_rate': [.1, .3, .5],\n",
    "         'lambda_l1': [.5, 1, 3, 5],\n",
    "         }\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "clf = GridSearchCV(estimator=lgbm, \n",
    "                   param_grid=params, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Best score: \", clf.best_score_)\n",
    "# lgbm.fit(X_train, y_train)\n",
    "# yhat_lgbm = lgbm.predict_proba(X_test)\n",
    "# roc_auc_score(y_test, yhat_lgbm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 87115, number of negative: 83025\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 785\n",
      "[LightGBM] [Info] Number of data points in the train set: 170140, number of used features: 222\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9016208210062866"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(boosting_type='dart', objective='binary', num_threads=10,lambda_l1=3,learning_rate=0.3, num_iterations=500)\n",
    "lgbm.fit(X_train, y_train)\n",
    "yhat_lgbm = lgbm.predict_proba(X_test)\n",
    "roc_auc_score(y_test, yhat_lgbm[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best parameters: {'max_depth': 30, 'n_estimators': 500}\n",
      "Best score:  0.8041260138709297\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [10, 50, 100, 500],\n",
    "           'max_depth': [None, 10, 20, 30]}\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "clf = GridSearchCV(estimator=rfc, \n",
    "                   param_grid=params,\n",
    "                   verbose=1, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Best score: \", clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8975438069629619"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=30, n_estimators=500)\n",
    "rfc.fit(X_train, y_train)\n",
    "yhat_rfc = rfc.predict_proba(X_test)\n",
    "roc_auc_score(y_test, yhat_rfc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 87115, number of negative: 83025\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 785\n",
      "[LightGBM] [Info] Number of data points in the train set: 170140, number of used features: 222\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 211\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 212\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 767\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 213\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Info] Number of positive: 69692, number of negative: 66420\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 769\n",
      "[LightGBM] [Info] Number of data points in the train set: 136112, number of used features: 214\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512020 -> initscore=0.048087\n",
      "[LightGBM] [Info] Start training from score 0.048087\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n",
      "[LightGBM] [Warning] lambda_l1 is set=3, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.905122927529621"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('lgbm',LGBMClassifier(boosting_type='dart', objective='binary', num_threads=10,lambda_l1=3,learning_rate=0.3, num_iterations=500)),\n",
    "    ('rf', RandomForestClassifier(max_depth=30, n_estimators=500))\n",
    "]\n",
    "stacker = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=xgb, passthrough=True\n",
    ")\n",
    "stacker.fit(X_train, y_train)\n",
    "yhat_stack = stacker.predict_proba(X_test)\n",
    "roc_auc_score(y_test, yhat_stack[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
